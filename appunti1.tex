\documentclass[a4paper,10pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{xfrac}
\usepackage[all]{xy}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{fullpage}
\usepackage{hyperref}
\usepackage[utf8x]{inputenc}
\usepackage[italian]{babel}

\usepackage{pdftricks}
\begin{psinputs}
   \usepackage{pstricks}
   \usepackage{multido}
\end{psinputs}

\usepackage{ulem}

\setlength{\parindent}{0in}

\newcounter{counter1}

\theoremstyle{plain}
\newtheorem{myteo}[counter1]{Teorema}
\newtheorem{mylem}[counter1]{Lemma}
\newtheorem{mypro}[counter1]{Proposizione}
\newtheorem{mycor}[counter1]{Corollario}
\newtheorem*{myteo*}{Teorema}
\newtheorem*{mylem*}{Lemma}
\newtheorem*{mypro*}{Proposizione}
\newtheorem*{mycor*}{Corollario}

\theoremstyle{definition}
\newtheorem{mydef}[counter1]{Definizione}
\newtheorem{myes}[counter1]{Esempio}
\newtheorem{myex}[counter1]{Esercizio}
\newtheorem*{mydef*}{Definizione}
\newtheorem*{myes*}{Esempio}
\newtheorem*{myex*}{Esercizio}

\theoremstyle{remark}
\newtheorem{mynot}[counter1]{Nota}
\newtheorem{myoss}[counter1]{Osservazione}
\newtheorem*{mynot*}{Nota}
\newtheorem*{myoss*}{Osservazione}

\newcommand{\obar}[1]{\overline{#1}}
\newcommand{\ubar}[1]{\underline{#1}}

\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\pa}[1]{\left(#1\right)}
\newcommand{\ang}[1]{\left<#1\right>}
\newcommand{\bra}[1]{\left[#1\right]}
\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\norm}[1]{\left\|#1\right\|}

\newcommand{\pfrac}[2]{\pa{\frac{#1}{#2}}}
\newcommand{\bfrac}[2]{\bra{\frac{#1}{#2}}}
\newcommand{\psfrac}[2]{\pa{\sfrac{#1}{#2}}}
\newcommand{\bsfrac}[2]{\bra{\sfrac{#1}{#2}}}

\newcommand{\der}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\pder}[2]{\pfrac{\partial #1}{\partial #2}}
\newcommand{\sder}[2]{\sfrac{\partial #1}{\partial #2}}
\newcommand{\psder}[2]{\psfrac{\partial #1}{\partial #2}}

\newcommand{\intl}{\int \limits}

\DeclareMathOperator{\de}{d}
\DeclareMathOperator{\id}{Id}
\DeclareMathOperator{\len}{len}

\DeclareMathOperator{\gl}{GL}
\DeclareMathOperator{\aff}{Aff}
\DeclareMathOperator{\isom}{Isom}


\title{Colloquio 3 - appunti1}
\author{Enrico Polesel}
\date{\today}

\begin{document}
\maketitle

\section{Distanza di Hausorff}

Ipotesi: $(M,d)$ spazio metrico.

Ipotesi: $\Omega \subseteq M$ chiuso

\begin{mydef}[Distanza di un punto da un insieme]
Dato $A \subseteq \Omega$ non vuoto definiamo:

\[  d_A (x) := \inf _{y \in A} d(x,y) \] 
\end{mydef}

\textbf{Idea:} forme $\leftrightarrow$ sottoinsiemi chiusi
$\leftrightarrow$ funzioni $d_A$

\begin{mydef}[Spazio di forme]
  \[ C_d(\Omega) = \set{d_A : A \subseteq \Omega,\; A \neq \emptyset} \]
\end{mydef}

\begin{mypro}[Proprietà della distanza punto-insieme]
  Vale:
  \begin{itemize}
  \item La funzione $x \rightarrow d_A(x)$ è 1-Lipschitz (e quindi
    continua)
  \item $d_{A\cup B}(x) = \min\set{d_A(x),d_B(x)}$
  \item $\set{x:d_A(x) = 0} = \bar A$
  \item $d_A \equiv 0 \Rightarrow $ è denso in $\Omega$
  \item $d_{\bar A} = d_A$
  \item $A\subseteq B \Rightarrow d_A \ge d_B$
  \item $\bar A \subseteq \bar B \Leftrightarrow d_A \ge d_B$
  \item $d_A = d_B \Leftrightarrow \bar A = \bar B$
  \end{itemize}
\end{mypro}
\begin{proof} [Dimostrazione di $\set{x:d_A(x) = 0} = \bar A$]
  \`E ovvio che $x\in \bar A \Rightarrow d_A(x) = 0$ perché 
  \[ \forall \varepsilon > 0\; \exists y \in a \cap B(x,\varepsilon)
  \Rightarrow \forall \varepsilon > 0 \; d_A(x) \le d(x,y) <
  \varepsilon \]

  Sia $x\not\in \bar A$, allora esiste $\varepsilon>0$ tale che
  $B(x,\varepsilon) \cap A = \emptyset$. Allora $d_A(x) \ge
  \varepsilon$.
\end{proof}

\begin{proof}[Dimostrazione di $\bar A \subseteq \bar B
  \Leftrightarrow d_A \ge d_B$]
  Essendo $d_B \ge 0$ si ha che $d_A = 0 \Rightarrow d_B = 0$. Ma
  questo significa che 
  \[ x \in \bar A \Rightarrow x \in \bar B \]

  Se $\bar A \subseteq \bar B$ assumiamo wlog $A = \bar A, B = \bar B$
  (le funzioni distanza non cambiano passando alla chiusura). Allora
  la disuguaglianza è verificata perché stiamo facendo l'$\inf$ su due
  insiemi contenuti.  
\end{proof}


\begin{mylem}
\label{lem:infmincompatto}
  Se $A$ è compatto allora l'$\inf$ della definizione di $d_A$ è in
  realtà un $\min$, cioè:
  \[ \forall x \in \Omega \; \exists y \in A \ :\ d(y,x) = d_A(x) \]
\end{mylem}
% \begin{proof}
%   Se $d_A(x) = \delta$ allora esiste $\pa{a_n}_{n\in \mathbb{N}}$ con
%   $a_n \in A$ tale che
%   \[ d(a_n,x) < \delta + \frac{1}{n} \] 
%   Ma, per compattezza, estraiamo una sottosuccessione
%   $\pa{a_{n_k}}_{k\in \mathbb{N}}$ che converge ad un punto in $A$ che
%   chiamiamo $\bar a$.  Allora, scelto $n_k$ tale che $d(a_{n_k},\bar
%   a) < \frac{1}{n}$ e che $n_k > n$ si ha
%   \[ d(x,\bar a) \le d\pa{x,a_{n_k}} + d\pa{a_{n_k}, \bar a} \le
%   \frac{1}{n_k} + \frac{1}{n} \le \frac{2}{n} \]
%   Per $n \to \infty$ si ha $d(x,\bar a) \le \delta$, ma $\bar a \in A$
%   dà la disuguaglianza opposta da cui $\bar a$ è il punto cercato.
% \end{proof}
\begin{proof}
  $d_A$ è una funzione continua su un compatto, quindi ha minimo.
\end{proof}

\begin{mylem}\label{lem:pallechiusecompattemin}
  Se in $M$ le palle chiuse sono compatte, dato $A$ chiuso l'$\inf$
  della definizione di $d_A$ è un minimo.
\end{mylem}
\begin{proof}
  Dato $x\in M$ supponiamo $d_A(x) < \infty$ (altrimenti la tesi è
  ovvia). Allora è evidente che possiamo cercare tale minimo in 
  \[ A \cap \bar B\pa{x,2 d_A(x)} \]
  che è compatto per ipotesi.
\end{proof}

\begin{mynot}
  Se $A$ non è compatto ma è un chiuso allora, in generale, il lemma
  precedente non è verificato. Costriuisco un controesempio in $l^2$
  
  Sia, per $n\in \mathbb{N}$ $a_n$ la successione con $1+\frac{1}{n}$
  all'$n$-esimo posto e $0$ altrove. Sia $A = \set{a_n : n\in
    \mathbb{N}}$. Si pu\`o dimostrare che $A$ \`e chiuso utilizzando
  la propriet\`a $\bar A = \set {d_A = 0}$ oppure, più semplicemente,
  perché contiene tutti i suoi punti di accumulazione.

  Considero l'origine:
  \[ d_A(O) = \inf _{n\in \mathbb{N}} \norm{a_n}_2 = \inf _{n\in
    \mathbb{N}} \pa{1+\frac{1}{n}}^2 = 1 \]
  Però $\forall n\in \mathbb{N}\; d(O,a_n) > 1$ e quindi non si
  raggiunge il minimo per nessun punto.  
\end{mynot}

\begin{mynot}
  In uno spazio vettoriale di dimensione finita il lemma
  \ref{lem:infmincompatto} vale chiedendo solo che $A$ sia chiuso
  applicando il lemma \ref{lem:pallechiusecompattemin}.
\end{mynot}


\begin{myoss}
  Usare le funzioni $d_A$ per classificare gli insiemi significa
  vederli a meno di chiusure, quindi quozientiamo per
  \[ A \approx B \Leftrightarrow \bar A = \bar B \] 

  È ovvio che possiamo prendere come rappresentate di una classe
  l'\textit{unica} chiusura di ogni insieme, quindi abbiamo
  \[ \sfrac{\set{A \subseteq \Omega}}{\approx} \cong C_s(\omega) := \set{A
    \subseteq \Omega,\ A\text{ chiuso},\; A\neq \emptyset} \]
\end{myoss}
\begin{mypro}
  \[ C_s(\Omega) \cong C_d(\Omega) \]
  \[ A \rightarrow d_A \]
\end{mypro}
\begin{proof}
  La mappa è sicuramente ben definita e surgettiva per come è definito
  $C_d(\Omega)$. Per l'iniettività ci basta osservare che se $d_A =
  d_B$ con $A,B \in C_s(\Omega)$ allora $\bar A = \bar B$, ma $A$ e $B$
  sono chiusi da cui la tesi.
\end{proof}



\begin{mydef}[Distanza di Hausdorff]
  Dati due insiemi $A,C \subseteq \Omega$ definiamo
%  \[ d_H (A,C) = \norm{ d_A - d_C } _\infty = \sup _{x\in \Omega}
%  \set {d_A(x) - d_C(x)}\]
%
%  Anzi, la definisco come:
  \[ d_H(A,C) = \max \set{\sup _{x\in A} d_C (x) , \sup _{x\in C} d_A
    (x) } \]
\end{mydef}

In seguito dimostrerò che $d_H$ è una funzione distanza

Notazione: definisco (con un abuso di linguaggio):
\[ A + \bar B_\varepsilon := \set{ x \in \Omega : \exists y \in A :
  d(x,y) \le \varepsilon }\]
Questa uguaglianza vale, infatti, in $R^N$ e, più in generale, in
spazi vettoriali reali.

Osservo che se $A$ è chiuso vale
\[ A = \bar B _{\varepsilon} = \set{ x \in \Omega \mid d_A(x) \le
  \varepsilon} \] 


\begin{mypro}
  Se $A, C$ sono \sout{compatti} \sout{chiusi} le seguenti definizioni
  sono equivalenti
  \begin{enumerate}
  \item $ d_H (A,C) = \norm{ d_A - d_C } _\infty = \sup _{x\in \Omega}
    \set {d_A(x) - d_C(x)}$
  \item $d_H(A,C) = \max \set{\sup _{x\in A} d_C (x) , \sup _{x\in C}
      d_A (x) }$
  \item $d_H (A,C) = \inf \set{\delta : A \subseteq C + \bar B
    _\delta \wedge C \subseteq A + \bar B_\delta} = \max \set{\inf
    \set{\delta : A \subseteq C + \bar B _\delta }, \inf \set{\delta : C
      \subseteq A + \bar B _\delta }}  $
  \end{enumerate}
\end{mypro}

\begin{proof}
  \textbf{$2 \sim 3$} Basta dimostrare che $\sup _{x\in A} d_C(x) =
  \inf \set{ \delta : A \subseteq C + \bar B _{\delta}}$.

  Se $\sup _{x\in A} d_C(x) = \alpha$ allora
  \[ \forall x \in A, \; d_C (x) \le \alpha \Rightarrow \pa{\forall
    \varepsilon > 0 \exists y \in C \mid d(x,y) < \alpha +
    \varepsilon} \Rightarrow \pa{\forall \varepsilon > 0 \; x
    \in C + \bar B _{\alpha + \varepsilon}}\]
  Valendo questa relazione $\forall x \in A$ si ha
  \[ \pa{\forall \varepsilon > 0 \; A \subseteq C + \bar B _{\alpha +
      \varepsilon}} \Rightarrow \inf \set{ \delta : A \subseteq C +
    \bar B _{\delta}} \le \alpha \]

  D'altra parte se $\varepsilon > 0$ allora $\exists x \in A$ tale che
  $d_C(x) > \alpha - \varepsilon$. Allora
  \[ \alpha - \varepsilon < \inf_{y\in C}\set{d(x,y)} \Rightarrow
  \forall y \in C\; d(x,y) > \alpha - \varepsilon \Rightarrow x\not\in
  C + \bar B_{\alpha - \varepsilon} \Rightarrow \inf \set{ \delta : A
    \subseteq C + \bar B _{\delta}} \ge \alpha - \varepsilon\]
  Per $\varepsilon \rightarrow 0$ si ha quindi l'altra disuguaglianza
  ottenendo la tesi.

  \textbf{$1\sim 2$}
  Sia $\max \set{\sup _{x\in A} d_C (x) , \sup _{x\in C} d_A (x) } =
  \delta$.
  
  Voglio valutare $\sup_{x\in \Omega} \abs{d_A(x)-d_C(x)}$.

  Primo caso: $x\in A$. Allora
  \[ d_A(x) = 0 \Rightarrow \abs{d_A(x)-d_C(x)} = d_C(x) \le \sup
  _{x\in A} d_C (x) \le \delta \]
  Secondo caso: $x\in C$, in modo analogo al caso precedente otteniamo
  $\abs{d_A(x)-d_C(x)} \le \delta$.
  
  Caso generale: sia $x\in \Omega$, supponiamo wlog $d_A(x) \ge d_C(x)$
  (l'altro caso vale per simmetria). Quindi$\abs{d_A(x)-d_C(x)} =
  d_A(x)-d_C(x)$. Scegliendo $y \in C$ tale che $d(x,y) < d_C(x) +
  \varepsilon$ (con $\varepsilon > 0$) si ha
  \[ d_A(x)-d_C(x) \le d_A(y) + d(x,y) - d_C(x) < d_A(y) + d_C(x) +
  \varepsilon -d_C(x) = d_A(y) + \varepsilon\]
  Per $\varepsilon \rightarrow 0$ si ha $d_A(x) - d_C(x) \le d_A(x)
  \le \delta$.

  Dimostriamo ora che il $\sup_{x\in \Omega} \abs{d_A(x)-d_C(x)} \ge
  \delta$. Per farlo supponiamo wlog 
  \[ \delta = \max \set{\sup _{x\in A} d_C (x) , \sup _{x\in C} d_A
    (x) } = \sup _{x\in A} d_C (x) \] 
  (nell'altro caso si conclude con un ragionamento analogo).

  Quindi esiste $\pa{x_n}_{n\in\mathbb{N}}$, $x_n\in A$ tale che
  $d_C(x_n) > \delta - \frac{1}{n}$. Ma allora
  \[ \abs{d_A(x_n) - d_C(x_n)} = d_C(x_n) > \delta - \frac{1}{n} \]
  Facendo tendere $n$ all'infinito si ha la disuguaglianza cercata da
  cui la tesi.
\end{proof}

\begin{myoss}
  La distanza di Hausorff è definita, in realtà, su $\set{A \subseteq
    \Omega}$, su questo spazio, però, non è una distanza perché non
  distingue tra un insieme e la sua chiusura, quozientando per la
  relazione $\cong$ otteniamo una distanza in $C_s(\Omega)$.
\end{myoss}
\begin{proof}
  È ovvio che $d_H \ge 0$ e che $d_H(A,C) = d_H(C,A)$.

  Dimostriamo che $d_H(A,C) = 0 \Leftrightarrow A = C$: questo vale se
  $\norm{d_A - d_C}_\infty = 0$ che equivale a dire $d_A = d_C$ e
  quindi $\bar A = \bar C$ da cui un'implicazione perché $A,C$ sono
  chiusi, l'altra implicazione è invece ovvia.

  Per la triangolare osserviamo che, dati $A,B,C \subseteq \Omega$
  chiusi si ha
  \[ \abs{d_A(x) - d_C(x)} \le \abs{d_A(x) - d_B(x)} + \abs{d_B(x) -
    d_C(x)} \le d_H(A,B) + d_H(B,C) \]
  Da cui la tesi passando all'estremo superiore per $x\in \Omega$.
\end{proof}

\begin{mycor}
  La relazione $C_s(\Omega) \cong C_d(\Omega)$ è un'isometria usando su
  $C_d(\Omega)$ la distanza di Hausdorff su $C_s(\Omega)$ e la norma
  infinito su $C_d(\Omega)$
\end{mycor}

\begin{myoss}
  Per come l'abbiamo definita, la distanza di Hausdorff ha valori in
  $\mathbb{R}_0^+ \cup \set{+\infty}$.

  Se questo è un problema possiamo aggirarlo in due modi:
  \begin{itemize}
  \item Chiedendo $\Omega$ limitato 
  \item Prendendo come distanza fra $A$ e $C$ il valore $\min\set{ d_H
      (A,C) , M}$ con $M >0$
  \end{itemize}
\end{myoss}

Vogliamo studiare ora le propriet\`a di $C_s(\Omega) = C_d(\Omega)$ come
spazio metrico, iniziamo con la completezza:

\begin{myteo}[Completezza{\cite[Proposizione 4.4.2]{ambrosio2000selected}}]
  Se $(\Omega,d)$ è completo allora $\pa{C_s(\Omega),d_H}$ è completo.
\end{myteo}
\begin{proof}
  Sia $\pa{C_n}_{n\in \mathbb{N}} \subseteq C_s(\Omega)$ una successione
  di Cauchy rispetto a $d_H$, allora esiste $\pa{n_k}_{k\in
    \mathbb{N}}$ crescete tale che 
  \[ \forall n,m \ge N_k\;\; d_H(C_n,C_m) < 2^{-k} \] Scegliamo
  $x_1\in C_{N_1}$, siccome $d_H(C_{N_1},C_{N_2}) < \sfrac{1}{2}
  \Rightarrow d_{C_{N_2}}(x_1) < \sfrac{1}{2}$ allora esiste $x_2\in
  C_{N_2}$ tale che $d(x_1,x_2) < \sfrac{1}{2}$. Induttivamente
  possiamo scegliere una successione $\pa{x_k}_{k\in \mathbb{N}}$ tale
  che $d(x_k,d_{k+1})<2^{-k}$ che è quindi di Cauchy e, per
  completezza di $\Omega$, converge ad un qualche $\bar x\in \Omega$.

  Definiamo ora 
  \[ D_k:= \obar{ \bigcup_{j \ge k} C_{N_j}} \]
  $\forall j \ge k$ si ha $x_j\in D_k$ e quindi, siccome $D_k$ è
  chiuso, $\forall k\;\; \bar x\in D_k$.

  Sia $C:=\bigcap _k D_k$, questo insieme è chiuso (perché
  intersezione di chiusi) e non vuoto (perché $\bar x\in
  C$). Dimostriamo che $C$ è il limite cercato dando una maggiorazione
  di $d_H(C,C_{N_k})$.

  \[ x\in C \Rightarrow x \in D_k \Rightarrow d_{C_{N_k}}(x) \le
  \frac{1}{2^k} \]
  Dove nell'ultima implicazione usiamo il fatto che $\forall j \ge k
  \; d_H(C_{N_k},C_{N_j}) < \frac{1}{2}$ ottenendo la disuguaglianza
  $\forall x \in \bigcup_{j \ge k} C_{N_j}$, ma per la triangolare di
  $d_{C_k}$ questa disuguaglianza vale passando alla chiusura.
  
  D'altra parte $\forall j\ge k$, sempre per $d_H(C_{N_j},C_{N_k}) <
  \frac{1}{2^k}$
  \[ \forall x \in C_{C_{N_k}}\; d_{C_{N_j}}(x) < \frac{1}{2^k}
  \Rightarrow d_{D_{j}}(x) < \frac{1}{2^k} \]
  Mettendo insieme le due disuguaglianze si ottiene
  \[ d_H(C_{N_k},C) < \frac{1}{2^k} \]
  
  Ma allora $\forall k \in \mathbb{N}$ si ha $\forall n \ge N_k$
  \[ d_H(C_n,C) \le d_H(C_n,C_{N_k}) + d_H(C_{N_k},C) \le
  \frac{1}{2^k} + \frac{1}{2^k} = \frac{1}{2^{k-1}} \]
  Da cui la tesi per l'arbitrarietà di $k$
\end{proof}

Diamo un risultato di compattezza:
\begin{myteo}[Blaschke{\cite[Teorema 4.4.6]{ambrosio2000selected}}]
  \label{teo:spazioformecompatto}
  Se $\Omega$ è compatto allora $C_s(\Omega)$ è compatto nella metrica
  di Hausdorff
\end{myteo}
\begin{proof}
  Siccome $\Omega$ è compatto allora è completo e totalmente limitato,
  se dimostriamo che anche $C_s(\Omega)$ è totalmente limitato abbiamo
  la tesi perché il teorema precedente ci da la completezza di
  $C_s(\Omega)$.

  Dato $\varepsilon >0$ sia $F\subseteq \Omega$ insieme finito dei centri di
  una $\varepsilon$-rete che ricopre $\Omega$. Vogliamo dimostrare che
  $\mathcal{F}:= \mathcal{P}(F)$ è l'insieme dei centri di una
  $\varepsilon$-rete finita che ricopre $C_s(\Omega)$ secondo $d_H$.

  Sia $C\in C_s(\Omega)$, siccome è chiuso è anche compatto. Considero
  le palle aperte di centro $F\cap C$ e raggio $\varepsilon$, questo è
  un ricoprimento di $C$ e ne estraggo quindi un sottoricoprimento
  finito di centri $D=\set{d_1,...,d_n} \in \mathcal{F}$. Per
  costruzione del sottoricoprimento si ha $C \subseteq D +
  \bar B_\varepsilon$, d'altra parte $D \subseteq C$. Quindi
  \[ \forall C \in C_s(\Omega)\; \exists D \in \mathcal{F}\text{ t.c. }
  d_H(C,D) < \varepsilon \]
  Cioè abbiamo trovato una $\varepsilon$-rete in $C_s(\Omega)$ da cui la
  totale limitatezza.
\end{proof}

La compattezza di $C_s(\Omega)$ è molto comoda, infatti ci dice che
tutte le funzioni semicontinue inferiormente ammettono minimo.

Mostro, per esempio, che il numero di componenti connesse è una
funzione s.c.i. in $C_s(\Omega)$, inzio con un lemma.

\begin{mylem}
  Dati $A,B \subseteq \Omega$ chiusi con almeno uno dei due compatto e
  $A \cap B = \emptyset$ allora
  \[ \inf _{x\in A} d_B(x) = \inf _{(x,y) \in A\times B} d(x,y) = \inf
  _{y\in B} d_A(y) >0 \]
\end{mylem}
\begin{proof}
  Sia $A$ compatto, allora $x \to d_B(x)$ ha minimo in $A$, sia $\bar
  x \in A$ tale minimo. Se $d_B(\bar x) = 0$ allora $\bar x \in \bar B = B$
  contro l'ipotesi $A \cap B = \emptyset$
\end{proof}

Sia $K(\Omega) = \set{K\subseteq \Omega :\; K \text{ compatto}}$.

\begin{mypro}
  La funzione $f:\; K(\Omega) \rightarrow \mathbb{N} \cup \set{+\infty}$
  che ad un compatto associa il numero delle sue componenti connesse è
  semicontinua inferiormente
\end{mypro}
\begin{proof}
  Dobbiamo dimostrare che la controimmagine di $\left(n-1,
    +\infty\right]$ è chiusa qualunque sia $n>0$, questo equivale a
  dimostrare che la controimmagine di $\bra{n,+\infty}$ è aperta.

  Chiamiamo $I = f^{-1}\pa{\bra{n,+\infty}}$.

  Sia quindi $A \in I$, vogliamo dimostrare che esiste un intorno
  aperto di $A$ in $I$.

  Se troviamo $\varepsilon$ tale che $A + \bar B_{\varepsilon} \in I$
  allora ogni $D \subseteq A + \bar B_{\varepsilon}$ avrà almeno $n$
  componenti connesse, quindi anche questo varrà anche per $\set{D \in
    C(\Omega):\; d_H(A,D) < \varepsilon}$ per la relazione
  \[ \set{D \in C(\Omega):\; d_H(A,D) < \varepsilon} \subseteq \set{D
    \in C(\Omega):\; D \subseteq A + \bar B_{\varepsilon}} \]

  Separiamo le componenti connesse in $n$ gruppi includendole in $n$
  chiusi $A_1,A_2,...,A_n$ (chiusi nella topologia di $\Omega$) tali
  che non si intersechino a due a due. Iniziamo prendendo un chiuso
  che contenga tutte le componenti connesse, cioè $A$, se $n=1$
  abbiamo finito, altrimenti (per la definizione di connessione)
  possiamo dividere questo chiuso in due chiusi con le proprietà
  richieste, infatti esistono $\tilde A_1, \tilde A_2$ aperti e chiusi
  nella topologia indotta in $A$ tali che $A = \tilde A_1 \cup \tilde
  A_2$ e che $\tilde A_1 \cap \tilde A_2 = \emptyset$, ma siccome $A$
  è chiuso in $\Omega$ si ha che $\tilde A_1, \tilde A_2$ sono chiusi
  nella topologia di $\Omega$.

  Iteriamo questa costruzione dividendo ogni volta un chiuso che
  contiene più di una componente connessa fermandoci quando otteniamo
  $n$ insiemi. Possiamo arrivare ad otterne $n$ perché, per ipotesi,
  $A$ ha almeno $n$ componenti connesse. Inoltre, per costruzione, $A
  = A_1 \cup A_2 \cup ... \cup A_n$.

  Avendo $A_1,A_2,..., A_n \subseteq A$ chiusi ed essendo $A$ compatto
  per ipotesi allora anche gli $A_1, ..., A_n$ sono compatti e quindi
  per il lemma precedente le distanze di Hausdorff reciproche di $A_1,
  ..., A_n$ sono non nulle, sia $\delta$ il minimo di queste distanze
  e scegliamo $\varepsilon = \sfrac{\delta}{3}$. Ma allora questo è il
  $\varepsilon$ cercato, infatti $\pa{A_1\cup ... \cup A_n} + \bar B
  _\varepsilon$ ha ancora almeno $n$ componenti connesse e di
  conseguenza le ha anche $A + \bar B_{\varepsilon}$ per la relazione
  \[ A + \bar B_{\varepsilon} = \pa{A_1\cup ... \cup A_n} + \bar
  B_\varepsilon\]
\end{proof}
\begin{mycor}
  Limite di insiemi connessi è connesso.
\end{mycor}

TODO: per il chiusi non vale, esempio iperboli

% TODO: l'area invece non è così. Esempio rettangoli che si dimezzano
% e si addensano

\section{Geodetiche}

Sia ancora $(M,d)$ uno spazio metrico dove vogliamo definire le
geodetiche, per farlo inziamo definendo la lunghezza di una curva
$\gamma :\; \bra{a,b} \to M$
\begin{mydef}[Lunghezza di una curva]
  \[ \len^d \gamma := \sup _{\mathcal{P}_{fin}(\bra{a,b}) \ni T =
    \set{t_1 \le t_2 \le ... \le t_n}} \sum_{i=1}^n d\pa{
    \gamma\pa{t_{i-1}}, \gamma\pa{t_i}} \]
\end{mydef}

Chiamiamo $\Gamma (x,y) = \set{\gamma:\; \bra{a,b} \to M \mid
  \gamma(a) = x, \gamma(b) = y,\; \gamma \text{ continua}}$

\begin{mydef}[Distanza geodetica indotta]
  \[ d^g (x,y) := \inf _{\gamma \in \Gamma(x,y)} \len^d \gamma \]
\end{mydef}

\begin{myoss}
  Dalla triangolare otteniamo che 
  \[ \forall \gamma \in \Gamma(x,y) \; \len^d \gamma \ge d(x,y) \]
  Passando all'$\inf$ ottentiamo quindi
  \[ d^g(x,y) \ge d(x,y) \]
  Comunque scegliamo $x,y \in M$.
\end{myoss}

\begin{myoss}
\label{oss:topologiagedoeticafine}
  Da $d^g \ge d$ otteniamo che la topologia generata da $d^g$ è più
  fine di quella generata da $d$ e, di conseguenza, se un insieme è
  compatto con la distanza $d^g$ allora lo è anche con la distanza
  $d$.
\end{myoss}

In generale non vale l'uguaglianza $d = d^g$, e cambia anche la
topologia. Mostro che un compatto opportuno $M \subseteq \mathbb{R}^2$
con la metrica euclidea indotta non è compatto nella topologia delle
geodetiche.

\begin{myes}[{\cite[Esempio 2.1]{DuciMennucci2007}}]
\label{es:topologiageodeticadiversa}
  Sia $E = \bra{0,1} \times \pa{ \set{0} \cup \set{ \frac{1}{n} \mid n
      > 0} }$ e $\psi(\rho,\theta) = \rho
  \pa{\cos(\theta),\sin(\theta)}$. Considero quindi $M = \psi(E)$.

  $M$ è unione di segmenti di lunghezza $1$, passanti per l'origine
  con inclinazione decrescente che tendono al segmento orrizzontale
  (accumolandosi). 

  \begin{figure}[h]
    \centering
    \begin{pdfpic}
      \begin{pspicture}(0,0)(10,10)
        \psline[linewidth=0.04cm](0.0,0.0)(8.0,0.0)
        \psline[linewidth=0.02cm](0.0,0.0)(4.322418,6.731768)
        \psline[linewidth=0.02cm](0.0,0.0)(7.020660,3.835404)
        \psline[linewidth=0.02cm](0.0,0.0)(7.559656,2.617558)
        \psline[linewidth=0.02cm](0.0,0.0)(7.751299,1.979232)
        \psline[linewidth=0.02cm](0.0,0.0)(7.840533,1.589355)
        \psline[linewidth=0.02cm](0.0,0.0)(7.889146,1.327169)
        \psline[linewidth=0.02cm](0.0,0.0)(7.918506,1.138974)
        \psline[linewidth=0.02cm](0.0,0.0)(7.937581,0.997398)
        \psline[linewidth=0.02cm](0.0,0.0)(7.950668,0.887061)
        \psline[linewidth=0.02cm](0.0,0.0)(7.960033,0.798667)
        \psline[linewidth=0.02cm](0.0,0.0)(7.966965,0.726271)
        \psline[linewidth=0.02cm](0.0,0.0)(7.972238,0.665895)
        \psline[linewidth=0.02cm](0.0,0.0)(7.976343,0.614778)
        \psline[linewidth=0.02cm](0.0,0.0)(7.979601,0.570943)
        \psline[linewidth=0.02cm](0.0,0.0)(7.982229,0.532938)
        \psline[linewidth=0.02cm](0.0,0.0)(7.984380,0.499675)
        \psline[linewidth=0.02cm](0.0,0.0)(7.986163,0.470317)
        \psline[linewidth=0.02cm](0.0,0.0)(7.987657,0.444216)
        \psline[linewidth=0.02cm](0.0,0.0)(7.988922,0.420858)
        \psline[linewidth=0.02cm](0.0,0.0)(7.990002,0.399833)
        \psline[linewidth=0.02cm](0.0,0.0)(7.990931,0.380808)
        \psline[linewidth=0.02cm](0.0,0.0)(7.991737,0.363511)
        \psline[linewidth=0.02cm](0.0,0.0)(7.992440,0.347717)
        \psline[linewidth=0.02cm](0.0,0.0)(7.993057,0.333237)
        \psline[linewidth=0.02cm](0.0,0.0)(7.993601,0.319915)
        \psline[linewidth=0.02cm](0.0,0.0)(7.994084,0.307616)
        \psline[linewidth=0.02cm](0.0,0.0)(7.994514,0.296229)
        \psline[linewidth=0.02cm](0.0,0.0)(7.994899,0.285654)
        \psline[linewidth=0.02cm](0.0,0.0)(7.995244,0.275807)
        \psline[linewidth=0.02cm](0.0,0.0)(7.995556,0.266617)
        \psline[linewidth=0.02cm](0.0,0.0)(7.995838,0.258020)
        \psline[linewidth=0.02cm](0.0,0.0)(7.996094,0.249959)
        \psline[linewidth=0.02cm](0.0,0.0)(7.996327,0.242387)
        \psline[linewidth=0.02cm](0.0,0.0)(7.996540,0.235260)
        \psline[linewidth=0.02cm](0.0,0.0)(7.996735,0.228540)
        \psline[linewidth=0.02cm](0.0,0.0)(7.996914,0.222194)
        \psline[linewidth=0.02cm](0.0,0.0)(7.997078,0.216190)
        \psline[linewidth=0.02cm](0.0,0.0)(7.997230,0.210502)
        \psline[linewidth=0.02cm](0.0,0.0)(7.997370,0.205106)
        \psline[linewidth=0.02cm](0.0,0.0)(7.997500,0.199979)
        \psline[linewidth=0.02cm](0.0,0.0)(7.997621,0.195103)
        \psline[linewidth=0.02cm](0.0,0.0)(7.997733,0.190458)
        \psline[linewidth=0.02cm](0.0,0.0)(7.997837,0.186030)
        \psline[linewidth=0.02cm](0.0,0.0)(7.997934,0.181803)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998025,0.177763)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998110,0.173899)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998189,0.170200)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998264,0.166655)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998334,0.163254)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998400,0.159989)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998462,0.156853)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998521,0.153837)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998576,0.150934)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998628,0.148140)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998678,0.145447)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998725,0.142850)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998769,0.140344)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998811,0.137924)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998851,0.135587)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998889,0.133327)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998925,0.131142)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998959,0.129027)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998992,0.126979)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999023,0.124995)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999053,0.123072)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999082,0.121207)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999109,0.119399)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999135,0.117643)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999160,0.115938)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999184,0.114282)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999207,0.112672)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999228,0.111108)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999249,0.109586)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999270,0.108105)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999289,0.106664)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999307,0.105260)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999325,0.103893)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999343,0.102561)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999359,0.101263)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999375,0.099997)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999390,0.098763)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999405,0.097559)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999419,0.096383)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999433,0.095236)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999446,0.094115)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999459,0.093021)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999472,0.091952)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999483,0.090907)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999495,0.089886)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999506,0.088887)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999517,0.087910)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999527,0.086955)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999538,0.086020)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999547,0.085105)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999557,0.084209)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999566,0.083332)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999575,0.082473)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999584,0.081631)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999592,0.080807)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999600,0.079999)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999608,0.079207)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999616,0.078430)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999623,0.077669)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999630,0.076922)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999637,0.076189)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999644,0.075471)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999651,0.074765)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999657,0.074073)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999663,0.073393)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999669,0.072726)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999675,0.072071)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999681,0.071428)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999687,0.070796)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999692,0.070175)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999698,0.069564)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999703,0.068965)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999708,0.068375)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999713,0.067796)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999718,0.067226)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999722,0.066666)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999727,0.066115)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999731,0.065573)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999736,0.065040)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999740,0.064515)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999744,0.063999)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999748,0.063491)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999752,0.062991)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999756,0.062499)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999760,0.062015)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999763,0.061538)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999767,0.061068)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999770,0.060605)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999774,0.060150)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999777,0.059701)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999781,0.059259)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999784,0.058823)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999787,0.058394)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999790,0.057971)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999793,0.057553)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999796,0.057142)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999799,0.056737)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999802,0.056338)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999804,0.055944)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999807,0.055555)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999810,0.055172)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999812,0.054794)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999815,0.054421)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999817,0.054054)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999820,0.053691)
      \end{pspicture}
    \end{pdfpic}

    \caption{L'insieme dell'esempio \ref{es:topologiageodeticadiversa}}
    \label{fig:topologiageodeticadiversa}
  \end{figure}

  $M$ è compatto nella metrica euclidea, nella metrica indotta dalle
  geodetiche, però, $M$ non è più compatto, infatti i punti $x_n =
  \psi(1,\frac{1}{n})$ non posso ammettere una sottosuccessione
  convergente essendo, per ogni $n\neq m$, $d^g(x_n,y_m) = 2$.
\end{myes}

Questo non esclude che in alcuni casi $d = d^g$, per esempio
\begin{mypro}
  $\pa{d^g}^g = d^g$
\end{mypro}
\begin{proof}
  Basta dimostrare che $\forall x,y \in M$ si ha $\pa{d^g}^g(x,y) \le
  d^g(x,y)$.

  Sia $\tilde\gamma \in \Gamma(x,y)$ tale che $\len ^d \tilde\gamma <
  d^g(x,y) + \varepsilon$, voglio stimare la sua lunghezza in $d^g$,
  prendo quindi $\set{t_0,t_1,...,t_n} \subseteq \bra{a,b}$ tale che
  \[ \sum _{i=1} ^n d^g(\tilde\gamma(t_{i-1}),\tilde\gamma(t_i)) \ge
  \len ^{d^g} \tilde\gamma - \varepsilon \] Per la relazione $d\le
  d^g$ ho:
  \[ \len ^{d^g} \tilde\gamma \le \varepsilon + \sum _{i=1} ^n
  d^g(\tilde\gamma(t_{i-1}),\tilde\gamma(t_i)) \le \varepsilon + \sum
  _{i=1} ^n d(\tilde\gamma(t_{i-1}),\tilde\gamma(t_i)) \le \varepsilon
  + \len ^d \tilde\gamma < 2 \varepsilon + d^g(x,y) \]

  Quindi
  \[ \pa{d^g}^g (x,y) = \inf _{\gamma \in \Gamma(x,y)} \len ^{d^g}
  \gamma \le \len ^{d^g} \tilde\gamma \le 2 \varepsilon + d^g(x,y) \]
  Mandando $\varepsilon \to 0$ si ha la tesi.
\end{proof}

\begin{mydef}[Metrica intrinseca]
  Se la distanza $d$ è tale che $d = d^g$ si dice che $(M,d)$ è una
  metrica intrinseca
\end{mydef}

Per i prossimi risultati userò questi fatti facilemente dimostrabili:
\begin{mylem}
  Data $\gamma:\; \bra{a,b} \to M$ continua si ha $\forall c \in
  \pa{a,b}$
  \[ \len ^d (\gamma_{|\bra{a,c}}) +  \len ^d (\gamma_{|\bra{c,b}}) = 
  \len ^d (\gamma) \] 
\end{mylem}
\begin{mylem}
  Se $\tilde \gamma \in \Gamma (x,y)$ con $\len ^d (\tilde \gamma) = L
  < \infty$ e $\tilde \gamma : \; \bra {a,b} \to M$ allora si può
  riparametrizzare $\tilde \gamma$ in $\gamma : \bra{0,L} \to M$ con la
  proprietà $\len ^d(\gamma_{| \bra{0,t}}) = t$.
\end{mylem}
% \begin{proof}
%   Considero la funzione $t:\bra{a,b} \to \bra{0,L}$ tale che $t(s) =
%   \len ^d (\gamma_{|\bra{0,s}})$ questa funzione è evidentemente
%   crescente e si può verificare che è continua. Quindi posso definire
%   \[ \gamma = \tilde \gamma \circ f^{-1} \]
% \end{proof}
\begin{mylem}
  Con la riparametrizzazione del lemma precedente si ha, presi $0 \le
  t < s \le \len ^d (\gamma)$
  \[ \len ^d (\gamma _{|\bra{t,s}}) = s - t \]
\end{mylem}

E ora un risultato sulla relazione tra intrinsecità di $(M,d)$ e
quella di $\pa{C_s(M),d_H}$
\begin{mypro}
  La metrica di $(M,d)$ è intinseca se e solo se è intrinseca la
  metrica di $(C_s(M),d_H)$
\end{mypro}
\begin{proof}
  Iniziamo dimostrando che $(M,d)$ intrinseca implica $(C_s(M),d_H)$
  intrinseca.

  Siano $A,C \in C_s(M)$ e sia $\mu = d_H(A,C)$ e scegliamo
  $\varepsilon >0$, allora (per la definizione di $d_H$) possiamo dire
  che
  \[ \forall x \in A\; \exists y \in C \mid d(x,y) < \mu +
  \varepsilon \]
  Analogamente per $C$:
  \[ \forall y \in C\; \exists x \in A \mid d(x,y) < \mu +
  \varepsilon \]
  Quindi, detto
  \[ P = \set{(x,y)\in A\times C:\; d(x,y) < \mu + \varepsilon} \]
  Si ha che proiettando $P$ sulle prime componenti troviamo $A$ e
  proiettandolo sulla seconda troviamo $C$ (in generale però $P \neq A
  \times C$).  Siccome $\forall (x,y) \in P\; d^g(x,y) = d(x,y) \le \mu
  + \varepsilon$ (perché la metrica è intrinseca) possiamo dire che
  $\forall (x,y) \exists \gamma_{(x,y)}$ tale che $\len ^d \gamma \le
  \mu + 2 \varepsilon$. Scegliamo una curva per ogni coppia di punti e
  definiamo
  \[ \Gamma = \set{\gamma _{(x,y)} :\; (x,y) \in P} \]

  Senza perdere di generalità possiamo chiedere che, se la curva
  $\gamma \in \Gamma$ ha lunghezza $\alpha (\mu + 2
  \varepsilon )$, allora $\len ^d \pa{ \gamma _{|\bra{s,t}}} = \alpha
  (t-s)$. Tutte le curve $\gamma$ avranno domino $\bra{0,\mu
    + 2 \varepsilon}$

  Definiamo ora, al variare di $t\in \bra{0,\mu + 2 \varepsilon}$
  \[ G(t) = \set{\gamma (t) | \; \gamma \in \Gamma} \;\;\;\; \bar G(t)
  = \obar{ G(t)} \]

  \`E evidente che $\bar G(0) = A$ e $\bar G(\mu + 2 \varepsilon) =
  C$, vogliamo ora dimostrare che $\bar G:\; \bra{0,\mu + 2
    \varepsilon} \to C_s(M)$, \`e continua e ha lunghezza minore di
  $\mu + 2 \varepsilon$.
  
  Dimostriamo che $\forall s<t \in \bra{0,\mu + 2 \varepsilon}$ si ha
  $d_H(\bar G(s),\bar G(t)) = d_H(G(s),G(t)) \le t-s$:
  \[ \forall \gamma(s) \in G(s) \; d_{G(t)}(\gamma(s)) = \inf _{y \in
    G(t)} d(\gamma(s),y) \le d(\gamma(s),\gamma(t)) = \alpha
  _{\gamma} (t-s) \le t-s \]
  Ripetendo lo stesso ragionamento per $G(s)$ otteniamo
  \[ d_H(G(s), G(t)) = \max\set{\sup_{x\in G(t)} d_{G(s)}(x) , \sup
    _{x\in G(s)} (x) d_{G(t)} } \le t-s \]
  Questo implica che $\bar G$ è $1$-Lipschitz e quindi
  continua. D'altra parte si ha che per ogni $t_0< t_1< ... < t_n \in
  \bra{0,\mu + 2 \varepsilon}$ 
  \[ \sum _{i=1} ^n d_H(\bar G(t_{i-1}), \bar G(t_i)) \le \sum _{i=1}
  ^n (t_i - t_{i-1}) = t_n - t_0 \le \mu + 2\varepsilon \]
  Quindi $\len ^{d_H}(\bar G) \le \mu + 2 \varepsilon$.
  Essendo $\bar G$ una curva continua in $C_s(M)$ che congiunge $A$ e
  $C$ si ha $d_H ^g (A,C) \le \mu + 2\varepsilon $, quindi
  \[ \mu = d_H (A,C) \le d_H^g(A,C) \le \mu + 2\varepsilon \]
  Mandando $\varepsilon \to 0$ si ha l'uguaglianza cercata.

  Dimostriamo l'altra implicazione: siano $a,c\in M$ e sia $\mu =
  d(a,c)$ consideriamo i razionali nella forma
  \[ Q = \set{ \mu \frac{k}{2^n}|\; 0< k <2^n\; k\text{ dispari}} \cup
  \set{0,\mu}\]

  E definiamo, induttivamente $\tilde \gamma:\; Q \to M$ in modo che
  $d(\tilde \gamma (t), \tilde \gamma (s)) < \abs{s-t} + \varepsilon
  \frac{\abs{s-t}}{\mu}$.

  Iniziamo definendo $\tilde\gamma \pa{\mu \frac{0}{2^0}} = a$, $\tilde\gamma
  \pa{\mu \frac{1}{2^0}} = c$, è evidente la proprietà sulla distanza.

  Supponendo di aver definito $\tilde \gamma (\mu \frac{k}{2^{n-1}})$
  con $0 \le k \le 2^{n-1}$ definiamo $\tilde \gamma$ per $\mu
  \frac{k}{2^n}$ con $k$ dispari. Per ipotesi induttiva sono definiti
  $x = \tilde \gamma\pa{\mu \frac{k-1}{2^n}}$ e $y = \tilde
  \gamma\pa{\mu \frac{k+1}{2^n}}$, sia quindi $G$ una curva nella
  metrica di Hausdorff che congiunge gli insiemi $\set{x}$ e $\set{y}$
  di lunghezza minore di $\frac{k+1}{2^n} - \frac{k-1}{2^n} +
  \frac{\varepsilon}{2^{n-1}} = \frac{1}{2^{n-1}} +
  \frac{\varepsilon}{2^{n-1}}$ (lo possiamo fare perché $d\pa{x,y} <
  \frac{\mu}{2^{n-1}} + \frac{\varepsilon}{2^{n-1}}$, la
  disuguaglianza è stretta, $d_H(\set{x},\set{y}) = d(x,y)$ e la
  metrica $d_H$ è intrinseca) e parametrizzata in modo che $d_H(G(s),
  G(t)) = \abs{t-s}$ con $G(0) = x$. Scegliamo allora un punto $z =
  \tilde \gamma \pa{\frac{k}{2^n}}$ in $G\pa{\frac{1}{2^n}}$, si deve
  avere necessariamente che $d(x,z) \le \frac{\mu}{2^n} +
  \frac{\varepsilon}{2^n}$ e $d(y,z) \le \frac{\mu}{2^n} +
  \frac{\varepsilon}{2^n}$. La disuguaglianza con gli altri punti già
  scelti vale applicando la proprietà triangolare.

  Abbiamo quindi definito una curva $\tilde \gamma: \; Q \to M$, data
  la stima sulla distanza dei punti nell'immagine possiamo estendere
  questa funzione, per continuità, ad una curva $\gamma: \bra{0,\mu}
  \to M$ continua. Usando ancora la stima sulla distanza dei punti
  possiamo maggiorare la lunghezza di questa curva con $\mu +
  \varepsilon$, quindi
  \[ \mu = d(a,c) \le d^g(a,c) \le \len^d (\gamma) \le \mu +
  \varepsilon \]
  Mandando $\varepsilon$ a zero si ha l'altra implicazione.
\end{proof}

Dimostriamo ora un risultato sull'esistenza di geodetiche in $(M,d)$
spazio metrico completo
\begin{mylem}
  Se $M$ \`e completo e compatto nella topologia indotta dalla
  metrica $d^g$ allora $\forall x,y \in M$ esiste la geodetica che tra
  $x$ e $y$ nella metrica indotta da $d$.
\end{mylem}
\begin{proof}
  Osservo che $M$ è compatto anche nella topologia indotta da $d$
  (vedi osservazione \ref{oss:topologiagedoeticafine}).

  Sia $\mu = d^g(x,y)$ e $\pa{\gamma _n}_{n \in \mathbb{N}} \subseteq
  \Gamma (x,y)$ una successione di curve continue tali che $\len
  \gamma _n \le \mu + \frac{1}{2^n}$. A meno di riparametrizzare posso
  chidere che $\forall n \in \mathbb{N}$ sia $\gamma _n :\;
  \bra{0,\mu} \to M$ con $\len ^d \gamma _{|\bra{s,t}} = \frac{\len ^d
    \gamma _n}{\mu}\pa{t-s} = \alpha _\gamma \pa{s-t}$, osservo che
  $\alpha _\gamma = \frac{\len ^d \gamma _n}{\mu} \le 2$.

  Le funzioni $\pa{\gamma _n}_{n \in \mathbb{N}}$ sono equicontinue
  (perché tutte Lipschitziane di constante minore di $2$),
  equilimitate (perché a valori in $C_s(M)$ compatto) e definite sul
  compatto $\bra{0,\mu}$. Quindi, per il teorema di Ascoli-Arzelà
  esiste una sottosuccessione $\pa{\gamma _{n_k}} _{n_k \in
    \mathbb{N}}$ convergente uniformemente ad una funzione $\gamma$.

  È evidente che $\gamma \in \Gamma (x,y)$, ci basta dimostare che
  $\len ^d \gamma = \mu$. Sia quindi $\set{ t_0 < t_1<... < t_n}
  \subseteq \bra{0,\mu}$, per ogni $\varepsilon > 0$ sia $\bar k$ tale
  che per ogni $k >\bar k$ $\norm{\gamma_{n_k} - \gamma} <
  \frac{\varepsilon}{n}$, allora
  \begin{align*}
  \sum _{i=1} ^n d\pa{\gamma(t_{i-1}),\gamma(t_i)} & \le \sum _{i=1}
  ^n\bra{ d\pa{\gamma(t_{i-1}),\gamma_{n_k}(t_{i-1})} +
    d\pa{\gamma_{n_k}(t_{i-1}), \gamma_{n_k}(t_i)} + d\pa{\gamma_{n_k}(t_i,
      \gamma(t_i)} } \\ 
  & \le \sum _{i=1} ^n \bra{ 2\frac{\varepsilon}{n} +
    d\pa{\gamma_{n_k}(t_{i-1}), \gamma_{n_k}(t_i)}} \\
  & \le 2\varepsilon + \len^d \gamma _{n_k} \le 2 \varepsilon + \mu +
  \frac{1}{2^{n_k}}
  \end{align*}
  Mandando $k \to \infty$ e $\varepsilon \to 0$ si ottiene quindi
  \[ \sum _{i=1} ^n d\pa{\gamma(t_{i-1}),\gamma(t_i)} \le \mu \]
  Facendo il $\sup$ su tutti i sottinsiemi finiti di $\bra{0,\mu}$
  otteniamo quindi
  \[ \len ^d \gamma \le \mu \]
  D'altra parte $\mu = d^g (x,y)$, quindi $\len ^d (\gamma) = \mu$ e
  $\gamma$ è la geodetica cercata.
\end{proof}

Quindi una condizione sufficiente per l'esistenza di geodetiche è che
lo spazio metrico sia compatto e intrinseco, per esempio $C_s(\Omega)$
con $\Omega$ compatto e $d$ intrinseca.

\begin{myes}
\label{es:duegeodetiche}  
Ovviamente le geodetiche possono non essere uniche, basta pensare ad
una ``rete'': sia $R  = \bigcup _{n \in \mathbb{Z}} \set{(n,y) \mid y
  \in \mathbb{R}} \cup \bigcup _{n \in \mathbb{Z}} \set{(x,n) \mid x
  \in \mathbb{R}} \subseteq \mathbb{R}^2$ con la metrica euclidea. I
punti $(0,0)$ e $(1,1)$ possono essere congiunti con due geodetiche
distinte 

\begin{figure}[h]
  \centering
  \begin{pdfpic}
    \begin{pspicture}(0,0)(10,10)
      \psgrid[subgriddiv=0, gridlabels=0pt, gridwidth=0.02cm](-1,-1)(3,3)
      \psdot[dotsize=0.2cm](0,0)
      \rput(-0.5,0.2){$(0,0)$}
      \psdot[dotsize=0.2cm](1,1)
      \rput(1.5,1.2){$(1,1)$}
      \psline[linewidth=0.05cm]{->}(0,0)(0,1)(1,1)
      \psline[linewidth=0.05cm]{->}(0,0)(1,0)(1,1)
    \end{pspicture}
  \end{pdfpic}
  \caption{Le due geodetiche tra $(0,0)$ e $(1,1)$ dell'esempio \ref{es:duegeodetiche}}
  \label{fig:doppiageodeticagriglia}
\end{figure}
\end{myes}


Nel cercare l'esistenza di geodetiche può tornare utile il segunte
lemma
\begin{mylem}
  Dati $x,y \in M$ esiste una geodetica tra di loro in $M$ se e solo
  se esiste in $B(x,d^g(x,y) + \delta)$ con $\delta > 0$
  qualsiasi.
\end{mylem}
\begin{proof}
  Il ``solo se'' è facile, infatti tutti i punti di una geodetica in
  $M$ avranno distanza minore di $d^g(x,y)$ da $x$ e quindi staranno
  nella palla.

  Supponiamo, quindi, che esista la geodetica in in $B := B(x,d^g(x,y) +
  \delta)$ per un qualche $\delta > 0$. Questa sarà una
  geodetica anche in $M$ se e solo se $d_{|B}^g (x,y) = d^g(x,y)$, ma
  $\forall 0 < \varepsilon < \delta$ esiste, in $M$, una curva di
  lunghezza minore di $d^g(x,y) + \varepsilon$, per lo stesso
  ragionamento del punto precedente tutti i punti devono stare in $B$
  e quindi $d_{|B}^g (x,y) < d^g(x,y) + \varepsilon$, passando
  all'estremo inferiore si ha la tesi.
\end{proof}


Vediamo ora che, con opportune ipotesi, nella distanza di Hausdorff
esiste sempre la geodetica fra insiemi compatti, ma ne possono
esistere più che numerabili.

\begin{mypro}
  Se in $M$ le palle chiuse sono compatte allora esiste sempre la
  geodetica fra $A,C \in K(M)$.
\end{mypro}
\begin{proof}
  Per il lemma precedente la geodetica si può cercare in\footnote{Per
    ora cerco la geodetica in $C_s(M)$, poi dimostrerò che tale
    geodetica in realtà ha valori in $K(M)$}
  \[ \set{D \in C_s(M) \mid \; d_H(A,D) \le d_H(A,C) + \delta= \mu +
    \delta } \]

  Dalla relazione $d_H(A,D) \le \mu + \delta \Rightarrow D \subseteq A
  + \bar B _{\mu + \delta}$, ricordando che (per compattezza) $A \subseteq
  B(x_0,\rho)$ (per qualche $x_0 \in M$, $\rho >0$) si ha che possiamo
  cercare i punti di una geodetica fra i sottoinsiemi di
  \[ \Omega = \obar{B(x_0,\rho)} + \bar B _{\mu + \delta} = \obar{ B
    (x_0, \rho + \mu + \delta) } \]

  Ma $\Omega$ è compatto per ipotesi e quindi, per il lemma
  precedente, esiste una geodetica in $C_s(\Omega)$, osservando che
  $C_s(\Omega) = K(\Omega) \subseteq K(M)$ (perché sottinsiemi chiusi
  in un compatto) si ha che la geodetica trovata ha valori in $K(M)$.
\end{proof}

Come preannunciato le geodetiche possono essere anche più che
numerabili. Vediamo un esempio
\begin{myes}[{\cite[Esempio 2.17]{DuciMennucci2007}}]
  Considero $M = \Omega = \mathbb{R}^2$ con la distanza euclidea $d$,
  osservo che questa distanza è intrinseca e, di conseguenza, lo sarà
  anche $d_H$.

  Siano $A = \set{(0,y)\mid \; 0 \le y \le 2}$, $C = \set{(2,y)\mid \;
    0 \le y \le 1}$ e $D_t = \set{(1,y) \mid \; 0 \le y \le
    \frac{3}{2}} \cup \set{ (x,0) \mid \; 1 \le x \le t}$ al variare
  di $t \in \bra{1,\frac{\sqrt{5}}{2}}$.

  \begin{figure}[h]
    \centering
    
    \begin{pdfpic}
   \begin{pspicture}(0,0)(3,3)
     \psline[linewidth=0.04cm](0.0,0.0)(0.0,2.0)
     \rput(-0.3,2){$A$}
     \psline[linewidth=0.04cm](2.0,0.0)(2.0,1.0)
     \rput(2.3,1){$C$}
     \psline[linewidth=0.04cm](1.0,0.0)(1.0,1.5)
     \psline[linewidth=0.04cm](0.98,0.0)(1.1,0.0)
     \rput(1.35,0.1){$D_t$}
     \psarc[linewidth=0.02cm,linestyle=dashed](0.0,2.0){1.118}{360.0}{180.0}
     \psarc[linewidth=0.02cm,linestyle=dashed](0.0,0.0){1.118}{180.0}{360.0}
     \psline[linewidth=0.02cm,linestyle=dashed](-1.118,0)(-1.118,2)
     \psline[linewidth=0.02cm,linestyle=dashed](+1.118,0)(+1.118,2)
     \psarc[linewidth=0.02cm,linestyle=dashed](2.0,1.0){1.118}{360.0}{180.0}
     \psarc[linewidth=0.02cm,linestyle=dashed](2.0,0.0){1.118}{180.0}{360.0}
     \psline[linewidth=0.02cm,linestyle=dashed](0.88197,0)(0.88197,1)
     \psline[linewidth=0.02cm,linestyle=dashed](3.118,0)(3.118,1)
   \end{pspicture}
\end{pdfpic}



    \caption{Gli insiemi $A,C,D_t$ e $A + \bar B _{\frac{\sqrt{5}}{2}},
        C + \bar B _{\frac{\sqrt{5}}{2}}$}
      \label{fig:esempioinfinitegeodetiche}
  \end{figure}
  Allora $\forall t$ si ha
  \[ d_H(A, D_t) = d_H (C, D_t) = \frac{\sqrt{5}}{2} = \frac{1}{2}
  d_H(A,C) \]
  Quindi, per ogni $t$, possiamo scegliere una geodetica $\gamma_t ^1$
  che congiunge $A$ e $D_t$, una $\gamma _t ^2$ che congiunge $C$ e
  $D_t$, incollandole otteniamo una geodetica fra $A$ e $C$. Quindi,
  abbiamo geodetiche distinte per ogni $t$ distinto e quindi più che
  numerabili geodetiche.
\end{myes}


Vediamo un caso in cui, invece, la geodetica esiste ed è unica
\begin{myes}
  Sia $V$ uno spazio di Banach strettamenete convesso, allora presi
  comunque $x,y \in V$ l'unica geodetica è il segmento che li unisce.
\end{myes}
\begin{proof}
  È facile verificare che il segmento che congiunge due punti è una
  geodetica, infatti questo può essere scritto come $\lambda \to
  \lambda x + \pa{1 - \lambda} y$ e la lunghezza è $\norm{x-y}$
  infatti $\forall \lambda _1, \lambda _2$
  \[ \norm{ \bra{ \lambda _1 x + \pa{ 1 - \lambda _1} y } - \bra{
      \lambda _2 x + \pa{ 1 - \lambda _2} y } } = \norm{\pa{\lambda _1
      - \lambda _2 } \pa{ x - y}} = \pa{ \lambda _1 - \lambda _2}
  \norm { x -y} \]

  Per dimostrare che è unica ci basta dimostrare che il punto medio è
  unico (si conclude iterando il ragionamento e poi per
  continuità). Supponiamo, a meno di translare e riscalare, che $y =
  -x$ e $\norm{x} = 1$, allora $d(x,y) = 2$ e il punto medio è $0$.

  Sia $\Gamma(x,y) \ni \gamma :\; \bra{-1,1} \to V$ un'altra geodetica
  (quindi $\len ^d (\gamma) = 2$), senza perdere di generalità
  possiamo supporre che $\gamma$ sia tale che $\len ^d \gamma_{\mid
    \bra{t,s}} = s -t$.

  Sia quindi $z = \gamma(0)$, per come abbiamo scelto la
  parametrizzazione (ed essendo $\gamma$ geodetica) si deve avere
  $\norm{z-x} = \norm{z-y} = 1$. Per la disuguaglianza triangolare
  possiamo scrivere
  \[ \norm{z+x} \le \norm{z-y} + \norm{y+x} = 1 \]
  Supponiamo, per assurdo, che $z \neq 0$, allora $\norm{\pa{x+z} +
    \pa{x-z}} = \norm{2z} >0$, quindi i due punti $x+z$ e $x-z$ sono
  distinti e appartengono alla sfera unitaria, per la stretta
  convessità si ha che $1 > \norm{\frac{(x+z) + (x-z)}{2} } = \norm{x}
  = 1$, da cui l'assurdo.
\end{proof}



% \newpage
% \begin{mydef}[Convessità di Menger]
%   Uno spazio metrico $M$ si dice convesso secondo Menger se, dati
%   comunque $x,y \in M$ distinti esiste $z\neq x,y$ tale che
%   \[ d(x,z) + d(z,y) = d(x,y) \]
% \end{mydef}


% Sotto opportune ipotesi uno spazio è convesso secondo Menger se e solo
% se la metrica è intrinseca ed esiste sempre la geodetica fra due
% punti. Cioè vale il seguente teorema:

% \begin{myteo}[{\cite[Teorema 2.6.2]{papadopoulos2013metric}}]
%   Sia $M,d$ uno spazio metrico in cui ogni palla chiusa è
%   compatta. Allora le seguenti condizioni sono equivalenti:
%   \begin{enumerate}
%   \item $M$ è convesso secondo Menger
%   \item $\forall x,y \in M$ esiste $z\in M$ tale che 
%     \[ d(x,z) = d(y,z) = \frac{1}{2} d(x,y) \]
%   \item $\forall x,y \in M$ e $\forall \lambda \in \bra{0,1}$ esiste
%     $z\in M$ tale che $d(x,z) = \lambda d(x,y)$, $d(y,z) = (1-\lambda)
%     d(x,y)$ 
%   \item Dati $x,y \in M$ esiste $\gamma \in \Gamma(x,y)$ tale che
%     $\len ^d (\gamma) = d(x,y)$
%   \end{enumerate}
% \end{myteo}
% % \begin{proof}
% %   TODO
% % \end{proof}

% Vogliamo applicare il teorema precedente a $K(\Omega),d_H$ per
% dimostrare che se $d$ è intrinseca dove esiste sempre la geodetica fra
% due punti allora anche $d_H$ è intrinseca ed esiste sempre la
% geodetica fra due insiemi.

% \begin{mylem}\cite[Proposizione 2.16]{DuciMennucci2007}
%   Sia $\Omega$ completo. Dati $A,C \in K(\Omega)$ con $d_H(A,C) <
%   \infty$ per ogni $\lambda \in \bra{0,1}$ esiste $D\in K(\Omega)$
%   tale che
%   \[ d_H(A,D) = \lambda d_H(A,C) \; , \;\;  d_H(D,C) = (1-\lambda)
%   d_H(A,C) \] 
% \end{mylem}
% \begin{proof}
%   Sia $\mu = d_H(A,C)$

%   Consideriamo l'insieme
%   \[ D := \set{z\mid \exists x \in A, y\in C, d(x,y) \le \mu, d(x,z)
%     \le \lambda \mu, d(y,z) \le (1 - \lambda) \mu }\]
%   Questo insieme è non vuoto, infatti (per compattezza di $A,C$)
%   esistono sempre $x,y$ tali che $d(x,y) \le \mu$, allora $z$ che
%   soddisfi le condizioni esiste perché $d$ è intrinseca e ci basta
%   considerare una geodetica tra $x$ e $y$.

%   Dimostro che $d(A,D) \le \lambda \mu$: per come abbiamo definito $D$
%   si ha che $\forall z \in D\; d_A(z) \le \lambda \mu$, quindi
%   \[ \sup _{z\in D} d_A(z) \le \lambda \mu \] D'altra parte, dato
%   $x\in A$ esiste $y\in B$ tale che $d(x,y) \le \mu$, allora esiste
%   una geodetica tra $x$ e $y$ e quindi anche un punto $z$ tale che
%   $d(x,z) \le \lambda \mu$ da cui
%   \[ \sup _{x \in A} d_D(x) \le \lambda \mu \]
%   Quindi concludiamo $d_H(A,D) \le \lambda \mu$, con un ragionamento
%   analogo possiamo concludere che $d_H(D,C) \le (1 - \lambda) \mu$.
%   A questo punto osserviamo che nella relazione
%   \[ \mu = d_H(A,C) \le d_H(A,D) + d_H(D,C) \le \lambda \mu + (1 -
%   \lambda) \mu = \mu \]
%   I segni di disuguaglianza devono essere uguaglianze e quindi
%   otteniamo $d_H(A,D) = \lambda \mu$ e $d_H(D,C) = (1 - \lambda)
%   \mu)$.

%   Ci basta ora dimostrare che $D$ è compatto.
% \end{proof}

% \begin{mynot}
%   È semplice vedere che $d_H$ intrinseca ed esiste la geodetica
%   $\Rightarrow$ $d$ intrinseca ed esiste la geodetica. Quindi dobbiamo
%   chiedere che $d$ sia intrinseca.
% \end{mynot}


% Reference: \cite[p.12-14]{DuciMennucci2007}

\section{Distanza su spazi quozienti}

Sia $(M,d)$ uno spazio metrico e $G$ un gruppo che agisce su $M$,
definiamo una distanza su $\sfrac{M}{G}$ nel seguente modo
\[ \bar d (\bra{x}, \bra{y}) = \inf _{\tilde x \in \bra{x} , \tilde y
  \in \bra {y}} d(\tilde x , \tilde y) = \inf _ {g,h \in G} d(g(x),
h(y)) \]

Si ottiene facilmente che $\bar d$ è simmetrica, vedremo che le altre
proprietà di una distanza non saranno sempre verificate.

\begin{mydef}
  Si dice che $d$ è invariante rispetto a $G$ se
\[ \forall g \in G,\; \forall x,y \in M \;\; d(g(x),g(y)) = d(x,y) \]
\end{mydef}

Allora, se $d$ è invariante rispetto a $G$, possiamo scrivere
\[ \bar d (\bra{x}, \bra{y}) = \inf _ {g,h \in G} d(g(x), h(y)) =
\inf _{g \in G} d(x,g(y)) \]

Quella che abbiamo definito potrebbe non essere una distanza, si pensi
ad esempio $\mathbb{R}$ con $G = \mathbb{Q}$ che agisce con la somma,
allora $\bar d \pa{ \bra{0} , \bra{\sqrt{2}} } = 0$ ma $\bra{0} \neq
\bra{\sqrt{2}}$, anzi si ha $d \equiv 0$.

Una condizione necessaria è che le orbite siano chiuse, sia infatti
$\bra{x}$ un'orbita non chiusa e $y \not\in \bra{x}$ un suo punto di
accumulazione, allora se $\pa{ x_n} _{n \in \mathbb{N}} \subseteq
\bra{x}$ è tale che $x_n \to _n y$ si ha $d(x_n,y) \to _n 0$ e quindi
$\bar d(\bra{x},\bra{y} = 0$.

Questa non è però una condizione sufficiente, per esempio
\begin{myes}
  Consideriamo in $\mathbb{R}^2$ l'azione di $\mathbb{R}^+$ definita
  da
  \[ \beta \to \pa{ \pa{x,y} \to \pa{\beta x , \frac{1}{\beta}y } } \]
  Le orbite sono delle parabole con asintoti lungo gli assi (e quindi
  sono chiuse), in particolare $\pa{1,1} \neq \pa{1,-1}$ ma
  \[ \bar d( \bra{ \pa{ 1,1} } , \bra{ \pa {1, -1}} ) \le \inf _{\beta
    \in \mathbb{R}^+ } d\pa{ \pa{ \beta , \frac{1}{\beta} } , \pa{
      \beta , - \frac{1}{\beta}} } = \inf _{ \beta \in \mathbb{R}^+ }
  \frac{2}{\beta} = 0 \]
\end{myes}

Una condizione sufficiente per richiedere che $\bar d (\bra{x} , \bra
{y} ) = 0 \Leftrightarrow \bra{x} = \bra{y}$ è che le orbite siano
compatte
\begin{mypro}
  Se le orbite sono compatte allora $\bar d (\bra{x},\bra{y}) = 0
  \Leftrightarrow \bra{x} = \bra{y}$.
\end{mypro}
\begin{proof}
  \`E banale vedere che $\bar d (\bra{x}, \bra{x} ) = 0$.

  Siano $\bra{x}, \bra{y} \in \sfrac{M}{G}$ tali che $\bar d
  (\bra{x},\bra{y}) = 0$ e siano $\pa{x_n}_ {n\in \mathbb{N}}
  \subseteq \bra{x}$ e $\pa{y_n}_ {n\in \mathbb{N}} \subseteq \bra{y}$
  tali che $d(x_n,y_n) < \frac{1}{2^n}$, per compattezza possiamo
  trovare $\pa{n_k} _{k\in \mathbb{N}}$ tale che $\pa{x_{n_k}}_{k\in
    \mathbb{N}}$ e $\pa{y_{n_k}}_{k\in \mathbb{N}}$ siano convergenti,
  siano $\bar x \in \bra{x}$ e $\bar y\in \bra{y}$ i rispettivi
  limiti, allora necessariamente $\bar x = \bar y$ per la relazione
  sulle distanze e quindi $\bra{x} \cap \bra{y} \neq \emptyset$ da cui
  $\bra{x} = \bra{y}$.
\end{proof}

Anche chiedendo la compattezza delle orbite la funzione $\bar d$
potrebbe non rispettare la disuguaglianza triangolare
\begin{myes}
  Sia $M = \set{ -2 , -1, 1, 2}$, $G =
  \sfrac{\mathbb{Z}}{2\mathbb{Z}}$ che agisce tramite $\varphi$ con
  \[ \varphi _0 = \id \;\;\; \varphi _1 (-2) = -2 ,\; \varphi _1 (-1)
  = 1 ,\; \varphi _1 (1) = -1 ,\; \varphi _1 (2) = 2 \]
  Allora $\bar d ( \bra{-2}, \bra{2}) = 4$, ma
  \[ \bar d (\bra{-2} , \bra{1} ) + \bar d (\bra{1} , \bra{2} ) = 1 + 1
  = 2 < 4 = \bar d ( \bra{-2}, \bra{2}) \]
  Quindi la disuguaglianza triangolare non è verificata.
\end{myes}

La disuguaglianza triangolare è invece verificata senza aggiungere
ipotesi sulle orbite ma chiedendo ``solo'' che la distanza sia
invariante rispetto a $G$
\begin{mypro}
  Se $d$ è invariante rispetto a $G$ allora vale la disuguaglianza
  triangolare per $\bar d$.
\end{mypro}
\begin{proof}
  Siano $\bra{x}, \bra{y}, \bra{z} \in \sfrac{M}{G}$, allora $\forall
  g,h \in G$ si ha
  \[ d(x,g(z)) \le d(x,h(y)) + d(h(y),g(z)) = d(x,h(y)) +
  d(y,h^{-1}g(z) \]
  Facendo prima l'$\inf$ su $h\in G$ e poi l'$\inf$ su $g \in G$ si
  ottiene la disuguaglianza cercata.
\end{proof}

In realtà, quando $d$ è invariante rispetto a $G$, ci basta chiedere
che le orbite siano chiuse per ottenere che $\bar d$ è una distanza.

\begin{mypro}
  Se $d$ è invariante rispetto a $G$ e le orbite sono chiuse allora
  $\bar d$ è una distanza
\end{mypro}
\begin{proof}
  Abbiamo già visto che vale la simmetria e la triangolare, ci basta
  dimostare che $\bar d (\bra{x},\bra{y}) = 0 \Leftrightarrow \bra{x}
  = \bra{y}$, ancora una volta $\Leftarrow$ è facile, dimostriamo
  l'altra implicazione.

  Siano $\bra{x}, \bra{y}$ tali che $\bar d ( \bra{x} , \bra{y}) = 0$,
  sappiamo che questo significa che
  \[ \inf _{g \in G} d(x,g(y)) = 0 \]
  Ma questo significa che $x$ è aderente a $\set{g(y)\mid g \in G} =
  \bra{y}$, ma $\bra{y}$ è chiuso per ipotesi e quindi $x \in \bra{y}$
  da cui $\bra{x} = \bra{y}$ che è la tesi.
\end{proof}

Quindi lavoriamo nell'ipotesi che $d$ sia invariante per l'azione di
$G$ e che le orbite di $G$ siano chiuse in modo che $\bar d$ sia una
distanza.

Ci chiediamo se la topologia definita da $\bar d$ in $\sfrac{M}{G}$
coincida con la topologia quoziente indotta dalla topologia su $M$
data da $d$.
\begin{mypro}
  Se $d$ è invariante per l'azione di $G$ e le orbite sono chiuse
  allora la topologia quoziente di $\sfrac{M}{G}$ coincide con la
  topologia data da $\bar d$.
\end{mypro}
\begin{proof}
  Sia $\tau$ la topologia data da $\bar d$ e $\tau _Q$ la topologia
  quoziente della topologia su $M$.

  Dalla relazione $\bar d ( \bra{x}, \bra{y} ) \le d(x,y)$ si ha che
  la proiezione $\pi : M \to \sfrac{M}{G}$ è 1-Lipshitz, quindi
  continua, siccome $\tau _Q$ è la topologia più fine che rende
  continua tale funzione allora $\tau \subseteq \tau _Q$.

  Sia $A \in \tau _Q$, allora $\pi ^{-1}(A)$ è aperto. Per ogni
  $\bra{x} \in A$ consideriamo un $x \in \pi^{-1}(\bra{x}) \subseteq
  \pi ^{-1}(A)$, deve quindi esistere $\varepsilon >0$ tale che
  $B(x,\varepsilon) \subseteq \pi ^{-1}(A)$. Voglio dimostrare che
  $B(\bra{x}, \varepsilon ) \subseteq A$.

  Se, per assurdo, $\exists \bra{y} \in B(\bra{x}, \varepsilon )
  \setminus A$, detta $\delta = \bar d (\bra{x}, \bra{y}) <
  \varepsilon$ si ha che, per definizione di $\bar d$, $\exists g \in
  G$ tale che $d(x,g(y)) < \delta + \frac{\varepsilon - \delta}{2} <
  \varepsilon$, ma allora $g(y) \in B(x,\varepsilon) \subseteq \pi
  ^{-1} (A)$ da cui $\bra{y} = \bra{g(y)} \in A$ e quindi l'assurdo
  perché avevamo supposto $\bra{y} \not\in A$.
\end{proof}

\begin{myoss}
  Nella dimostrazione precedente abbiamo usato il fatto che le orbite
  siano chiuse solo per dire che $\bar d$ è una distanza, se non lo
  chiediamo allora lavoriamo con una pseudometrica, ma la
  dimostrazione funziona lo stesso e quindi le topologie coincidono
  anche in questo caso.
\end{myoss}

\begin{myoss}
  Se $d$ è invariante per l'azione di $G$ e $\bar d$ definisce una
  metrica su $\sfrac{M}{G}$ allora le orbite di $G$ sono chiuse,
  infatti esse sono controimmagini di punti che, in uno spazio
  metrizzabile, sono sempre chiusi.
\end{myoss}

Vediamo cosa possiamo dire delle curve su $\sfrac{M}{G}$, sulle
geodetiche e sulla distanza indotta $\bar d ^g$.

Iniziamo osservando che $\sfrac{M}{G}$ ``contiene'' le curve di $M$,
formalemente:
\begin{mylem}
  Dati $x,y \in M$ Ad ogni curva $\gamma \in \Gamma(x,y)$ possiamo
  associare una curva in $\Gamma(\bra{x}, \bra{y})$ tramite la
  composizione con la proiezione $\pi$ da $M$ in $\sfrac{M}{G}$ (che è
  una funzione continua)
  \[ 
     \xymatrix{I \ar[r]^\gamma \ar[dr] _{\bar \gamma}& M \ar[d]^\pi \\
              & \sfrac{M}{G}  
            }
            \]
  Detta $\bar \gamma$ la curva ottenuta si ha inoltre
  \[ \len ^{\bar d} \pa{ \bar \gamma} \le \len ^d \pa{\gamma } \]
\end{mylem}
\begin{proof}
  L'unica cosa da dimostrare è che $\len ^{\bar d} \pa{ \bar \gamma}
  \le \len ^d \pa{\gamma }$.
  
  Sia $\set{ t_0 < t_1 < ... < t_n } \subseteq I$, allora
  \[ \sum _{i = 1} ^n \bar d ( \bar \gamma ( t_{i-1}) , \bar \gamma
  (t_i) ) = \sum _{i = 1} ^n \bar d ( \bra{\gamma ( t_{i-1}) } , \bra{
    \gamma (t_i)} ) \le \sum _{i = 1} ^n d ( \gamma ( t_{i-1}) ,
  \gamma (t_i) )  \le \len ^d (\gamma) \]
  Passando al $\sup$ sulle parti finite di $I$ si ha la tesi.
\end{proof}

Con questo possiamo dimostrare
\begin{mypro}
  Se la metrica $d$ è intrinseca allora anche $\bar d$ è intrinseca.
\end{mypro}
\begin{proof}
  Siano $\bra{x}, \bra{y} \in \sfrac{M}{G}$, possiamo suppore (a meno
  di cambiare i rappresentanti) che $d(x,y) < \bar d (\bra{x}, \bra{y}
  ) + \varepsilon$ dove abbiamo scelto $\varepsilon > 0$.

  Per ipotesi esiste $\gamma \in \Gamma( x,y)$ tale che $\len ^d
  \gamma < d(x,y) + \varepsilon$, usando il lemma precedente
  concludiamo
  \[ \len ^{\bar d} (\bar \gamma) \le \len ^d (\gamma) < d(x,y) +
  \varepsilon < \bar d (\bra{x}, \bra{y}) + 2\varepsilon \]
  Ma possiamo fare lo stesso ragionamento $\forall \varepsilon >0$ da
  cui la tesi.
\end{proof}

\begin{mypro}
  Se le orbite sono compatte e $d$ è intrinseco allora l'esistenza
  delle geodetiche in $M$ implica l'esistenza delle geodetiche in
  $\sfrac{M}{G}$
\end{mypro}
\begin{proof}
  Basta seguire la dimostrazione precedente osservando che possiamo
  scegliere $x,y \in M$ tali che $d(x,y) = \bar d (\bra{x}, \bra{y})$
  per la compattezza delle orbite e $\gamma \in \Gamma\pa{x,y}$ tale che
  $\len ^d \gamma = d(x,y)$ per l'esistenza delle geodetiche.
\end{proof}

TODO: è vero che $\obar{d^g} = \bar d ^g$?

\subsection{Quozienti su insiemi di forme di $\mathbb{R}^N$}

Vorrei considerare le forme di $\mathbb{R}^N$ a meno di particolari
trasformazioni come rotazioni e translazioni.

Dato $G \subseteq \aff(\mathbb{R}^N)$ voglio definire $M(A)$ al
variare di $M \in G$ e $A \in C_s(\mathbb{R}^N)$. Un modo è:
\[ M(A) = \set{ Ma \mid a \in A } \]

Ho quindi, fissato $A \in C_s(\mathbb{R}^N)$ un'applicazione $G \to
C_s(\mathbb{R}^N)$, mi chiedo quando è continua. Un gruppo $G$ a cui
sono particolarmente interessato è il gruppo delle rotazioni, ma già
questa azione non è necessariamente continua
\begin{myes}
  Con $N = 2$ sia $A = \set{(0,x) \mid x \in \mathbb{R}}$, allora
  $\forall R_\theta \in SO(\mathbb{R},2)$ si vede facilmente che
  \[ d_H(A, R_\theta (A)) = + \infty \] 
  E quindi l'azione non è continua in $\id$.
\end{myes}

Mi limito, allora, a considerare i compatti $A \in K(\mathbb{R}^N)$.

\begin{mypro}
  Se $A \in K(\mathbb{R}^N)$ allora $\forall G < \gl (\mathbb{R}^N)$
  l'azione
  \begin{align*}
    G &\rightarrow K(\mathbb{R}^N) \\  
    M &\rightarrow M(A)
  \end{align*}
  è continua.
\end{mypro}
\begin{proof}
  L'immagine di quest'azione su dev'essere in $K(\mathbb{R}^N)$ perché
  $M\in G$ definiscono funzioni continue in $\mathbb{R}^N$.

  Sia $\norm{\cdot}$ una norma operatoriale matriciale\footnote{Cioè
    tale che $\norm{MN} \le \norm{M}\norm{N}$ e $\norm{Mx} \le
    \norm{M}\norm{x}$} su $G$, allora $\forall M \in G$
  \[ d_H(A, M(A)) \le \sup _{x \in A} d(x,Mx) = \sup _{x \in A}
  \norm{Mx -x} = \sup _{x \in A} \norm{ \pa{ M - \id} x } \le \norm{ M
    - \id } \sup _{x \in A} \norm{x} \]
  Dove la prima disuguaglianza è data da $d_A (M(x)) \le d (x,M(x))$
  (e la relazione simmetrica), la seconda da come è stata scelta la
  norma.

  Per la compattezza di $A$ si ha $\sup _{x \in A} \norm{x} < \infty$ e quindi
  l'applicazione è continua in $\id$, ma $G$ è un gruppo topologico e
  quindi ci basta verificare la continuità in $\id$.
\end{proof}

Per le translazioni in realtà non serve la compattezza della forma
\begin{mypro}
  Se $A \in C_s(\mathbb{R}^N)$ allora la funzione $f: \mathbb{R}^N \to
  C_s(\mathbb{R}^N)$ tale che $f(t) = A + t := \set { a + t \mid a \in
    A}$ è continua.
\end{mypro}
\begin{proof}
  È ovvio che l'immagine sia in $C_s(\mathbb{R}^N)$ perché il traslato
  di un chiuso è ancora chiuso.
  
  Mi basta dimostrare, essendo $\mathbb{R}^N$ un gruppo, che $f$ è
  continua in $\ubar{0}$.
  
  Usando un ragionamento analogo al precedente:
  \[ d_H(A, A+t) \le \sup _{x \in A} d(x, x+t) = \sup _{x \in A}
  \norm{x-(x+t)} = \norm{t} \]
  Da cui la tesi.
\end{proof}

\begin{mycor}
  Scelto $A \in K(\mathbb{R}^N)$ la funzione $f:\; \aff( \mathbb{R}^N)
  \to K(\mathbb{R}^N)$ tale che $f(M) = M(A)$ è continua.
\end{mycor}

Voglio ora cercare di applicare i risultati ottenuti per le distanze
su spazi quoziente al quoziente di $K(\mathbb{R}^N)$ sulle rotazioni e
translazioni.

\begin{mylem}
  La distanza di Hausdorff su $K(\mathbb{R}^N)$ è invariante per
  l'azione del gruppo delle isometrie di $\mathbb{R}^N$
\end{mylem}
\begin{proof}
  Si vede facilmente usando che la distanza $d$ su $\mathbb{R}^N$ è
  invariante per le isometrie.
\end{proof}

Voglio ora dimostrare che le orbite sono chiuse, cioè contengono tutti
i loro punti di accumulazione.

\begin{mylem}
  \label{lem:traslazionipiccole}
  Sia $A \in K(\mathbb{R}^N)$ e $\pa{ g_n} _{n \in \mathbb{N}}
  \subseteq \isom( \mathbb{R}^N)$ tale che $\pa{ g_n(A) } _{n \in
    \mathbb{N}}$ è una successione convergente, allora esiste $\delta
  < \infty$ tale che, le isometrie $\pa{ g_n} _{n\in \mathbb{N}}$
  utilizzano traslazioni di norma minore di $\delta$.
\end{mylem}
\begin{proof}
  Sia $\varepsilon > 0$ il raggio di una palla che contiene $A$,
  essendo la successione convergente esiste $\bar n$ tale che $\forall
  n \ge \bar n$ si ha $g_n(A) \subseteq A + \bar B _{\varepsilon}$, ma
  allora se $n \ge \bar n$ si ha $g_n(A) \subseteq B(\ubar{0},
  2\varepsilon)$.

  Da questo si ha che $\forall n \ge \bar n$ la norma della
  translazione utilizzata da $g_n$ è minore di $3 \varepsilon$, scelgo
  quindi $\delta$ come il massimo fra $3\varepsilon$ e la norma delle
  traslazioni usate da $g_n$ con $n< \bar n$, essendo questo un
  insieme finito si ha $\delta < \infty$.
\end{proof}

\begin{mylem}
  Il gruppo ortogonale 
  \[ O(\mathbb{R},N) = \set{ M \in \gl (\mathbb{R},N) \mid M M^t =
    \id } \]
  è compatto $\forall N \in \mathbb{N}$.
\end{mylem}
\begin{proof}
  Siccome $GL(\mathbb{R},N) \hookrightarrow \mathbb{R}^{N^2}$ ci basta
  dimostrare che $O(\mathbb{R},N)$ è chiuso e limitato.
  
  La chiusura è facile, infatti il gruppo è controimmagine di
  $\set{\id}$ tramite la funzione continua $MM^t$.

  Dalla relazione
  \[ 1 = \pa{MM^t}_{ii} = \sum _j M_{ij} M_{ij} = \sum _j M_{ij} ^2 \] 
  Si ottiene $\forall i,j$ che $\abs{M_{ij}} \le 1$ da cui la
  limitatezza.
\end{proof}

\begin{mypro}
  Dato $G \subseteq \isom(\mathbb{R}^N)$ chiuso le orbite generate
  dalla sua azione su $K(\mathbb{R}^N)$ sono chiuse.
\end{mypro}
\begin{proof}
  Sia $A \in K(\mathbb{R}^N)$ e $C$ un suo punto di accumulazione, in
  particolare esisteranno $\pa{g_n}_{n\in \mathbb{N}}$ tali che
  $g_n(A) \to _n C$ nella metrica $d_H$. Per il lemma
  \ref{lem:traslazionipiccole} possiamo assumere che esista $\delta >
  0$ tale che $\forall n \in \mathbb{N}$ l'isometria $g_n$ utilizzi una
  traslazione di norma minore di $\delta$.

  Detto $\tilde G$ l'insieme delle isometrie in $G$ che usando
  traslazioni di norma minore o uguale a $\delta$ si ha che questo è
  ancora un insieme chiuso in $\isom\pa{\mathbb{R}^N}$ in quanto
  sottoinsieme chiuso (perché controimmagine del chiuso
  $\bra{-\delta,\delta}$) di $G$ che a sua volta è chiuso in
  $\isom(\mathbb{R}^N)$. Ma inoltre questo insieme è compatto in
  quanto contenuto in $O(\mathbb{R},N) \times \bra{-\delta,\delta}^N$
  che è compatto perché prodotto di compatti.
  
  Quindi, detta $f:\; \isom(\mathbb{R}^N) \to K(\mathbb{R}^N)$ con
  $f(g) = g(A)$, si ha $\pa{ g_n(A) }_{n \in \mathbb{N}} \subseteq
  f(\tilde G)$. Ma $\tilde G$ è compatto e quindi lo è anche $f(\tilde
  G)$, quindi è anche chiuso, allora contiene tutti i suoi punti di
  accumulazione e quindi anche $B$. Ma $\tilde G \subseteq G$ da cui
  $C \in f(G)$ che è la tesi.
\end{proof}

\begin{myoss}
  Dal ragionamento precedente si vede facilmente che, dati $A,C \in
  K(\mathbb{R}^N)$, esiste $g \in G$ tale che $d_H \pa{A, g(C)} = \bar
  d _H \pa{ \bra{A}, \bra{C}}$.
\end{myoss}

\section{Media basata sulle distanze}

Sia $(M,d)$ spazio metrico.

Dati $a_1,a_2,... a_n \in M$ considero la quanità, al variare di $a
\in m$
\[ m_A (a) = \sum _{i = 1} ^n d(a,a_i)^2 \]

Ha senso discutere se esiste $a$ e, nel caso, se è unico. Osservo che
non si ha necessariamente l'unicità, mi basta considerare nella
distanza geodetica indotta due punti che possono essere collegati da
più di una geodetica, allora i punti medi delle geodetiche saranno
minimi per tale quantità, nell'esempio \ref{es:duegeodetiche} i punti
$(0,1)$ e $(1,0)$ sono i minimi di $m_A$.

\begin{myoss}
  La funzione $m_A$ è continua, infatti è composizione di funzioni
  continue.
\end{myoss}
% \begin{proof}
%   Siano $a_1,a_2,... a_n \in M$, voglio dimostrare la continuità in un
%   punto $a\in M$, sia quindi $\varepsilon >0$ e consideriamo i $\tilde
%   a \in M$ tali che $d(a,\tilde a) < \varepsilon$.

%   Da una parte si ha
%   \begin{align*}
%     m_A(\tilde a) =& \sum _{i = 1} ^n d(\tilde a,a_i)^2 \\\le& \sum
%     _{i = 1} ^n \pa{ d(a,a_i) + d(a,\tilde a)} ^2 \\=& \sum _{i = 1}
%     ^n d(a,a_i) ^2 + 2\sum _{i = 1} ^n d(a,a_i)d(a,\tilde a) + \sum
%     _{i = 1} ^n d(a,\tilde a)^2 \\\le& \sum _{i = 1} ^n d(a, a_i) ^2 +
%     2\varepsilon \sum _{i = 1} ^n d(a,a_i) + n\varepsilon ^2 \\=&
%     m_A(a) + \varepsilon \pa{ 2\sum _{i = 1} ^n d(a,a_i) +
%       n\varepsilon }
%   \end{align*}

%   Dall'altra:
%   \begin{align*}
%     m_A(\tilde a) =& \sum _{i = 1} ^n d(\tilde a,a_i)^2 \\\ge& \sum
%     _{i = 1} ^n \pa{ d(a,a_i) - d(\tilde a, a) } ^2 \\=& \sum _{i = 1}
%     ^n d(a,a_i) ^2 - 2\sum _{i = 1} ^n d(a,a_i)d(\tilde a, a) + \sum
%     _{i = 1} ^n d(\tilde a , a)^2 \\\ge& \sum _{i = 1} ^n d(a,a_i) ^2
%     - 2\sum _{i = 1} ^n d(a,a_i)d(\tilde a, a) \\\ge& m_A(a) -
%     2\varepsilon \sum _{i = 1} ^n d(a,a_i)
%   \end{align*}

%   Unendo le disugaglianze si ottiene:
%   \[ \abs{ m_A(\tilde a) - m_A(a) } \le \varepsilon \max \set{ \pa{
%       2\sum _{i = 1} ^n d(a,a_i) + n\varepsilon } , \pa{ 2 \sum _{i =
%         1} ^n d(a,a_i)} } = \varepsilon \pa{ 2\sum _{i = 1} ^n
%     d(a,a_i) + n\varepsilon } \]

%   Essendo $a$ e $a_1,...,a_n$ fissati si ha che $\sum _{i = 1} ^n
%   d(a,a_i)$ è costante, lo stesso vale per $n$ e quindi $\abs{
%     m_A(\tilde a) - m_A(a) }$ può essere reso piccolo a piacere
%   mandando $\varepsilon \to 0$.
% \end{proof}

Considero il caso particolare di $M = K(\mathbb{R}^N)$ con la distanza
di Hausdorff.

\begin{mypro}
  Dati $A_1, A_2,..., A_n \in K(\mathbb{R}^N)$ esiste $A \in
  K(\mathbb{R}^N)$ che minimizza la funzione
  \[ m(A) = \sum _{i =1} ^n d(A,A_i)^2 \]
\end{mypro}
\begin{proof}
  Sia $0 < r< \infty$ il raggio di una palla che che contiene tutti
  gli $A_i$ e $\Omega = B(\ubar{0},2r)$, considero la seguente
  partizione di $K(\mathbb{R}^N)$:
  \[ K(\mathbb{R}^N) = K(\Omega) \cup \pa{ K(\mathbb{R}^N) \setminus
    K(\Omega)} \]

  Se $A \in K(\mathbb{R}^N) \setminus K(\Omega)$ allora $\exists \bar
  x \in A \setminus \Omega$, da questo deduco che $\forall i$
  \[ d_H(A,A_i) \ge \sup _{x\in A} d_{A_i} (x) \ge d_{A_i} (\bar x)
  \ge d_{B(\ubar{0},r)} (\bar x) \ge r \]
  Quindi $m(A) \ge nr^2$.

  Osservo che $\set{0} \in K(\Omega)$ e $\forall i$ si ha
  $d_H(\set{0},A_i) \le r$. Allora $m(\set{0}) \le nr^2$.

  Essendo $\Omega$ compatto per il teorema
  \ref{teo:spazioformecompatto} anche $K(\Omega)$ è compatto e quindi
  $m$ ristretta a $K(\Omega)$ avrà un minimo $\bar A$. Dev'essere
  necessariamente $m(\bar A) \le m(\set{0}) \le nr^2$, quindi $\bar A$
  è anche minimo per $m$ non ristretta, infatti ho già dimostato che
  in $K(\mathbb{R}^N) \setminus K(\Omega)$ la funzione $m$ assume
  valori maggiori o uguali a $nr^2$.
\end{proof}

Considero ora il caso in ho quozientato $K(\mathbb{R}^N)$ per un
sottogruppo chiuso delle isometrie di $\mathbb{R}^N$.

\begin{mypro}
  Dato $G < \isom (\mathbb{R}^N)$ e $A_1,...,A_n \in K(\mathbb{R}^N)$
  esiste $A \in K(\mathbb{R}^N)$ che minimizza la funzione 
  \[ \bar m(\bra{A}) = \sum _{i =1} ^n \bar
  d_H(\bra{A},\bra{A_i})^2 \]
\end{mypro}
\begin{proof}
  Trovare il minimo di $\bar m(\bra{A})$ equivale a calcolare
  \[ \inf _{g_1,...,g_n \in G, A\in K(\mathbb{R}^N)} \sum _{ i = 1} ^n
  d_H(A,g_i(A_i)) \]

  Sia $0 < r< \infty$ il raggio di una palla che che contiene tutti
  gli $A_i$ e $\Omega = B(\ubar{0},(n+1)r)$, voglio dimostrare che mi
  basta considerare gli $A$ e i $g_i$ tali che $\forall i\;\; g_i(A)
  \subseteq \Omega$, per farlo dimostro che se $\exists j$ tale che
  $g_j(A) \setminus \Omega \neq \emptyset$ allora $\sum _{ i = 1} ^n
  d_H(A_i,g_i(A)) \ge nr^2$ e poi esibisco un caso in cui $\sum _{ i =
    1} ^n d_H(A_i,g_i(A)) \le nr^2$.

  Sia quindi $\bar x \in g_j(A) \setminus \Omega$, allora
  \[ d_H(A_j,g_j(A)) \ge d_{A_j}(\bar x) \ge (n+1)r - r = nr \]
  Da cui $\sum _{ i = 1} ^n d_H(A_i,g_i(A)) \ge n^2r^2 \ge nr^2$
  
  Considero ora $A = \set{0}$ e $\forall i\;\; g_i = \id$, allora
  \[ \sum _{ i = 1} ^n d_H(g_i(\set{0}), A_i) = \sum _{ i = 1} ^n
  d_H(\set{0}, A_i) \le nr^2 \]

  Quindi mi basta considerare $A\in K(\mathbb{R}^N)$ e $g_1,...,g_n
  \in G$ tali che $\forall i\;\; g_i(A) \subseteq \Omega$. Ma questo,
  a meno di sostituire $A$ con $g_1(A)$ vuol dire che mi basta
  considerare $A \in K(\Omega)$.

  Detta $\pi:\; K(\mathbb{R}^N) \to \sfrac{K(\mathbb{R}^N)}{G}$ la
  proiezione sul quoziente ho che, essendo $K(\Omega)$ compatto, anche
  $\pi\pa{K(\Omega)}$ è compatto e, quindi, $\bar m$ ammette minimo in
  tale insieme, per quanto dimostato prima questo è anche un minimo
  globale.
\end{proof}


\section{Applicazioni}

\subsection{$k$-mean clustering}

\begin{mydef}[Diagramma di Voronoi]
  Dato $(M,d)$ spazio metrico e $x_1,...,x_k \in M$ punti distinti
  definiamo diagramma di Voronoi il partizionamento
  \[ R_j = \set{ x\in M \mid \forall 1 \le i \le k \;\; d(x,x_j) \le
    d(x,x_i) } \]
\end{mydef}

Supponiamo $k$ tipi di forme (compatte) e $n$ campioni $\mathcal{A} =
\set{ A_1, A_2,..., A_n} \in K(\mathbb{R}^N)$ di esse, vorremmo
dividerli in $k$ insiemi $S_1,...,S_k$, uno per tipo. Che proprietà
deve avere tale partizione?

Per ogni insieme $S_j$ di punti vogliamo intanto scegliere un
rappresentate, per farlo scegliamo un punto medio basato sulla
distanza, sia esso $M_j$. Ha senso ora calcolare
\[ m_j = \sum _{A\in S_j} d(M_j,S_j)^2 \]

Ci aspettiamo che un criterio di ottimalità sia la quantità
\[ \sum _{j=1} ^k m_j \]

Ricostruendo i vari passaggi, supponiamo di avere dei rappresentanti
candidati $M_1,...,M_k$, allora possiamo partizionare lo spazio col
diagramma di Voronoi $R_1,...,R_k$ e di conseguenza partizionare i
campioni in
\[ S_j = \mathcal{A} \cap R_j \]
A questo punto definiamo la funzione obbiettivo come
\[ f(M_1,...,M_k) = \sum _{j = 1} ^k m_j = \sum _{j = 1} ^k \pa{ \sum
  _{A \in S_j} d(A,M_j)^2 } \]

A questo punto possiamo porci come obbiettivo il minimizzare tale
funzione obbiettivo al variare di $M_1,...,M_k \in K(\mathbb{R}^N)$.

Tale approcio ha due difetti:
\begin{itemize}
\item il numero di forme $k$ è un dato in ingresso
\item il problema così posto è NP-hard
\end{itemize}

\newpage

\bibliographystyle{alpha}
\bibliography{Selected_Topics_on_Analysis_in_Metric_Sp,Banach-like_metrics_and_metrics_of_compact_sets,Metric_Spaces_Convexity_and_Nonpositive}


\newpage

Cose da inserire:
\begin{itemize}
\item Cenno di dimostrazione che $d^g$ è una distanza
\end{itemize}

Cose possibili da fare:

\begin{itemize}
\item Vedere quando, nelle definizioni di $d_H$ gli $\inf$ e $\sup$ si
  possono trasformare in $\min$ e $\max$.
\item se per un $x \in M$ e $\forall \rho > 0$ l'insieme $\set{ y \mid
    d(x,y) \le \rho}$ è compatto allora $(M,d)$ è completo
\end{itemize}


Cose saltate che potrebbero essere inserite
\begin{itemize}
\item skeleton
  \begin{itemize}
  \item Lo skeleton è compatto
  \item caratterizzazione coi punti dove non esiste il gradiente di
    $d_A$
  \end{itemize}
\item Convergenza di kuratowski (ambrosio tilli p.77) è implicata
  dalla Hausdorff ed è equivalente in compatti
\item Distanza con segno: $b_A(x) = d_A(x) - d_{^cA}(x)$
\end{itemize}


Cose saltate che non vorrei inserire:
\begin{itemize}
\item $d_A$ è Frechet differenziabile q.o. e $\abs{\nabla d_A} \le 1$
\end{itemize}
\end{document}

