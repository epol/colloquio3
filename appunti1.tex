\documentclass[a4paper,10pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{xfrac}
\usepackage[all]{xy}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{fullpage}
\usepackage{hyperref}
\usepackage[utf8x]{inputenc}
\usepackage[italian]{babel}

\usepackage{ulem}

\setlength{\parindent}{0in}

\newcounter{counter1}

\theoremstyle{plain}
\newtheorem{myteo}[counter1]{Teorema}
\newtheorem{mylem}[counter1]{Lemma}
\newtheorem{mypro}[counter1]{Proposizione}
\newtheorem{mycor}[counter1]{Corollario}
\newtheorem*{myteo*}{Teorema}
\newtheorem*{mylem*}{Lemma}
\newtheorem*{mypro*}{Proposizione}
\newtheorem*{mycor*}{Corollario}

\theoremstyle{definition}
\newtheorem{mydef}[counter1]{Definizione}
\newtheorem{myes}[counter1]{Esempio}
\newtheorem{myex}[counter1]{Esercizio}
\newtheorem*{mydef*}{Definizione}
\newtheorem*{myes*}{Esempio}
\newtheorem*{myex*}{Esercizio}

\theoremstyle{remark}
\newtheorem{mynot}[counter1]{Nota}
\newtheorem{myoss}[counter1]{Osservazione}
\newtheorem*{mynot*}{Nota}
\newtheorem*{myoss*}{Osservazione}

\newcommand{\obar}[1]{\overline{#1}}
\newcommand{\ubar}[1]{\underline{#1}}

\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\pa}[1]{\left(#1\right)}
\newcommand{\ang}[1]{\left<#1\right>}
\newcommand{\bra}[1]{\left[#1\right]}
\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\norm}[1]{\left\|#1\right\|}

\newcommand{\pfrac}[2]{\pa{\frac{#1}{#2}}}
\newcommand{\bfrac}[2]{\bra{\frac{#1}{#2}}}
\newcommand{\psfrac}[2]{\pa{\sfrac{#1}{#2}}}
\newcommand{\bsfrac}[2]{\bra{\sfrac{#1}{#2}}}

\newcommand{\der}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\pder}[2]{\pfrac{\partial #1}{\partial #2}}
\newcommand{\sder}[2]{\sfrac{\partial #1}{\partial #2}}
\newcommand{\psder}[2]{\psfrac{\partial #1}{\partial #2}}

\newcommand{\intl}{\int \limits}

\DeclareMathOperator{\de}{d}
\DeclareMathOperator{\id}{Id}
\DeclareMathOperator{\len}{len}


\title{Colloquio 3 - appunti1}
\author{Enrico Polesel}
\date{\today}

\begin{document}
\maketitle

\section{Distanza di Hausorff}

Ipotesi: $(M,d)$ spazio metrico

Ipotesi: $\Omega \subseteq M$

\begin{mydef}[Distanza di un punto da un insieme]
\[  d_A (x) := \inf _{y \in A} d(x,y) \] 
\end{mydef}

\textbf{Idea:} forme $\leftrightarrow$ sottoinsiemi chiusi
$\leftrightarrow$ funzioni $d_A$

\begin{mydef}[Spazio di forme]
  \[ C_d(\Omega) = \set{d_A : A \subseteq \Omega} \]
\end{mydef}

\begin{mypro}[Proprietà della distanza punto-insieme]
  Vale:
  \begin{itemize}
  \item La funzione $x \rightarrow d_A(x)$ è 1-Lipschitz (e quindi
    $C^1$)
  \item $d_{A\cup B}(x) = \min\set{d_A(x),d_B(x)}$
  \item $\set{x:d_A(x) = 0} = \bar A$
  \item $d_A \equiv 0 \Rightarrow $ è denso in $\Omega$
  \item $d_{\bar A} = d_A$
  \item $A\subseteq B \Rightarrow d_A \ge d_B$
  \item $\bar A \subseteq \bar B \Leftrightarrow d_A \ge d_B$
  \item $d_A = d_B \Leftrightarrow \bar A = \bar B$
  \end{itemize}
\end{mypro}
\begin{proof} [Dimostrazione di $\set{x:d_A(x) = 0} = \bar A$]
  \`E ovvio che $x\in \bar A \Rightarrow d_A(x) = 0$ perché 
  \[ \forall \varepsilon > 0\; \exists y \in a \cap B(x,\varepsilon)
  \Rightarrow \forall \varepsilon > 0 \; d_A(x) \le d(x,y) <
  \varepsilon \]

  Sia $x\not\in \bar A$, allora esiste $\varepsilon>0$ tale che
  $B(x,\varepsilon) \cap A = \emptyset$. Allora $d_A(x) \ge
  \varepsilon$.
\end{proof}

\begin{proof}[Dimostrazione di $\bar A \subseteq \bar B
  \Leftrightarrow d_A \ge d_B$]
  Essendo $d_B \ge 0$ si ha che $d_A = 0 \Rightarrow d_B = 0$. Ma
  questo significa che 
  \[ x \in \bar A \Rightarrow x \in \bar B \]

  Se $\bar A \subseteq \bar B$ assumiamo wlog $A = \bar A, B = \bar B$
  (le funzioni distanza non cambiano passando alla chiusura). Allora
  la disuguaglianza è verificata perché stiamo facendo l'$\inf$ su due
  insiemi contenuti.  
\end{proof}


\begin{mylem}
  Se $A$ è compatto allora l'$\inf$ della definizione di $d_A$ è in
  realtà un $\min$, cioè:
  \[ \forall x \in \Omega \; \exists y \in A \ :\ d(y,x) = d_A(x) \]
\end{mylem}
\begin{proof}
  Se $d_A(x) = \delta$ allora esiste $\pa{a_n}_{n\in \mathbb{N}}$ con
  $a_n \in A$ tale che
  \[ d(a_n,x) < \delta + \frac{1}{n} \] 
  Ma, per compattezza, estraiamo una sottosuccessione
  $\pa{a_{n_k}}_{k\in \mathbb{N}}$ che converge ad un punto in $A$ che
  chiamiamo $\bar a$.  Allora, scelto $n_k$ tale che $d(a_{n_k},\bar
  a) < \frac{1}{n}$ e che $n_k > n$ si ha
  \[ d(x,\bar a) \le d\pa{x,a_{n_k}} + d\pa{a_{n_k}, \bar a} \le
  \frac{1}{n_k} + \frac{1}{n} \le \frac{2}{n} \]
  Per $n \to \infty$ si ha $d(x,\bar a) \le \delta$, ma $\bar a \in A$
  dà la disuguaglianza opposta da cui $\bar a$ è il punto cercato.
\end{proof}

\begin{mynot}
  Se $A$ non è compatto ma è un chiuso allora, in generale, il lemma
  precedente non è verificato. Costriuisco un controesempio in $l^2$
  
  Sia, per $n\in \mathbb{N}$ $a_n$ la successione con $1+\frac{1}{n}$
  all'$n$-esimo posto e $0$ altrove. Sia $A = \set{a_n : n\in
    \mathbb{N}}$. Si pu\`o dimostrare che $A$ \`e chiuso utilizzando
  la propriet\`a $\bar A = \set {d_A = 0}$ oppure, più semplicemente,
  perché contiene tutti i suoi punti di accumulazione.

  Considero l'origine:
  \[ d_A(O) = \inf _{n\in \mathbb{N}} \norm{a_n}_2 = \inf _{n\in
    \mathbb{N}} \pa{1+\frac{1}{n}}^2 = 1 \]
  Però $\forall n\in \mathbb{N}\; d(O,a_n) > 1$ e quindi non si
  raggiunge il minimo per nessun punto.  
\end{mynot}

\begin{mynot}
  In uno spazio vettoriale di dimensione finita il lemma vale
  chiedenso solo che $A$ sia chiuso, infatti tutti i punti $a_n$ della
  successione data dall'$\inf$ stanno in 
  \[ a_n \in A \cap \bar B(x,2\delta) \]
  Che è chiusa perché intersezione di chiusi, è limitata e quindi
  anche compatta. Da qui si conclude in modo analogo al lemma.
\end{mynot}


\begin{myoss}
  Usare le funzioni $d_A$ per classificare gli insiemi significa
  vederli a meno di chiusure, quindi quozientiamo per
  \[ A \approx B \Leftrightarrow \bar A = \bar B \] 

  È ovvio che possiamo prendere come rappresentate di una classe
  l'\textit{unica} chiusura di ogni insieme, quindi abbiamo
  \[ \sfrac{\set{A \subseteq \Omega}}{\approx} \cong C(\omega) := \set{A
    \subseteq \Omega,\ A\text{ chiuso}} \]
\end{myoss}
\begin{mypro}
  \[ C(\Omega) \cong C_d(\Omega) \]
  \[ A \rightarrow d_A \]
\end{mypro}
\begin{proof}
  La mappa è sicuramente ben definita e surgettiva per come è definito
  $C_d(\Omega)$. Per l'iniettività ci basta osservare che se $d_A =
  d_B$ con $A,B \in C(\Omega)$ allora $\bar A = \bar B$, ma $A$ e $B$
  sono chiusi da cui la tesi.
\end{proof}



\begin{mydef}[Distanza di Hausdorff]
  Dati due insiemi $A,C \subseteq \Omega$ definiamo
%  \[ d_H (A,C) = \norm{ d_A - d_C } _\infty = \sup _{x\in \Omega}
%  \set {d_A(x) - d_C(x)}\]
%
%  Anzi, la definisco come:
  \[ d_H(A,C) = \max \set{\sup _{x\in A} d_C (x) , \sup _{x\in C} d_A
    (x) } \]
\end{mydef}

Notazione: definiamo (con un abuso di linguaggio):
\[ A + \bar B_\varepsilon := \set{ x \in \Omega : \exists y \in A :
  d(x,y) \le \varepsilon }\]

\begin{mypro}
  Se $A, C$ sono \sout{compatti} \sout{chiusi} le seguenti definizioni
  sono equivalenti
  \begin{enumerate}
  \item $ d_H (A,C) = \norm{ d_A - d_C } _\infty = \sup _{x\in \Omega}
    \set {d_A(x) - d_C(x)}$
  \item $d_H(A,C) = \max \set{\sup _{x\in A} d_C (x) , \sup _{x\in C}
      d_A (x) }$
  \item $d_H (A,C) = \inf \set{\delta : A \subseteq C + \bar B
    _\delta \wedge C \subseteq A + \bar B_\delta} = \max \set{\inf
    \set{\delta : A \subseteq C + \bar B _\delta }, \inf \set{\delta : C
      \subseteq A + \bar B _\delta }}  $
  \end{enumerate}
\end{mypro}

\begin{proof}
  \textbf{$2 \sim 3$} Basta dimostrare che $\sup _{x\in A} d_C(x) =
  \inf \set{ \delta : A \subseteq C + \bar B _{\delta}}$.

  Se $\sup _{x\in A} d_C(x) = \alpha$ allora
  \[ \forall x \in A \; d_C (x) \le \alpha \Rightarrow \pa{\forall
    \varepsilon > 0 \exists y \in C \mid d(x,y) < \alpha +
    \varepsilon} \Rightarrow \pa{\forall \varepsilon > 0 \; x
    \in C + \bar B _{\alpha + \varepsilon}}\]
  Valendo questa relazione $\forall x \in A$ si ha
  \[ \pa{\forall \varepsilon > 0 \; A \subseteq C + \bar B _{\alpha +
      \varepsilon}} \Rightarrow \inf \set{ \delta : A \subseteq C +
    \bar B _{\delta}} \le \alpha \]

  D'altra parte se $\varepsilon > 0$ allora $\exists x \in A$ tale che
  $d_C(x) > \alpha - \varepsilon$. Allora
  \[ \alpha - \varepsilon < \inf_{y\in C}\set{d(x,y)} \Rightarrow
  \forall y \in C\; d(x,y) > \alpha - \varepsilon \Rightarrow x\not\in
  C + \bar B_{\alpha - \varepsilon} \Rightarrow \inf \set{ \delta : A
    \subseteq C + \bar B _{\delta}} \ge \alpha - \varepsilon\]
  Per $\varepsilon \rightarrow 0$ si ha quindi l'altra disuguaglianza
  ottenendo la tesi.

  \textbf{$1\sim 2$}
  Sia $\max \set{\sup _{x\in A} d_C (x) , \sup _{x\in C} d_A (x) } =
  \delta$.
  
  Voglio valutare $\sup_{x\in \Omega} \abs{d_A(x)-d_C(x)}$.

  Primo caso: $x\in A$. Allora
  \[ d_A(x) = 0 \Rightarrow \abs{d_A(x)-d_C(x)} = d_C(x) \le \sup
  _{x\in A} d_C (x) \le \delta \]
  Secondo caso: $x\in C$, in modo analogo al caso precedente otteniamo
  $\abs{d_A(x)-d_C(x)} \le \delta$.
  
  Caso generale: sia $x\in \Omega$, supponiamo wlog $d_A(x) \ge d_C(x)$
  (l'altro caso vale per simmetria). Quindi$\abs{d_A(x)-d_C(x)} =
  d_A(x)-d_C(x)$. Scegliendo $y \in C$ tale che $d(x,y) < d_C(x) +
  \varepsilon$ (con $\varepsilon > 0$) si ha
  \[ d_A(x)-d_C(x) \le d_A(y) + d(x,y) - d_C(x) < d_A(y) + d_C(x) +
  \varepsilon -d_C(x) = d_A(y) + \varepsilon\]
  Per $\varepsilon \rightarrow 0$ si ha $d_A(x) \le \delta$.

  Dimostriamo ora che il $\sup_{x\in \Omega} \abs{d_A(x)-d_C(x)} \ge
  \delta$. Per farlo supponiamo wlog 
  \[ \delta = \max \set{\sup _{x\in A} d_C (x) , \sup _{x\in C} d_A
    (x) } = \sup _{x\in A} d_C (x) \] 
  (nell'altro caso si conclude con un ragionamento analogo).

  Quindi esiste $\pa{x_n}_{n\in\mathbb{N}}$, $x_n\in A$ tale che
  $d_C(x_n) > \delta - \frac{1}{n}$. Ma allora
  \[ \abs{d_A(x_n) - d_C(x_n)} = d_C(x_n) > \delta - \frac{1}{n} \]
  Facendo tendere $n$ all'infinito si ha la disuguaglianza cercata da
  cui la tesi.
\end{proof}

\begin{mycor}
  La relazione $C(\Omega) \cong C_d(\Omega)$ è un'isometria usando su
  $C_d(\Omega)$ la distanza di Hausdorff su $C(\Omega)$ e la norma
  infinito su $C_d(\Omega)$
\end{mycor}

\begin{myoss}
  La distanza di Hausorff è definita, in realtà, su $\set{A \subseteq
    \Omega}$, su questo spazio, però, non è una distanza perché non
  distingue tra un insieme e la sua chiusura, quozientando per la
  relazione $\cong$ otteniamo una distanza in $C(\Omega)$.
\end{myoss}
\begin{proof}
  È ovvio che $d_H \ge 0$ e che $d_H(A,C) = d_H(C,A)$.

  Dimostriamo che $d_H(A,C) = 0 \Leftrightarrow A = C$: questo vale se
  $\norm{d_A - d_C}_\infty = 0$ che equivale a dire $d_A = d_C$ e
  quindi $\bar A = \bar C$ da cui un'implicazione perché $A,C$ sono
  chiusi, l'altra implicazione è invece ovvia.

  Per la triangolare osserviamo che, dati $A,B,C \subseteq \Omega$
  chiusi si ha
  \[ \abs{d_A(x) - d_C(x)} \le \abs{d_A(x) - d_B(x)} + \abs{d_B(x) -
    d_C(x)} \le d_H(A,B) + d_H(B,C) \]
  Da cui la tesi passando all'estremo superiore per $x\in \Omega$.
\end{proof}

Vogliamo studiare ora le propriet\`a di $C(\Omega) = C_d(\Omega)$ come
spazio metrico, iniziamo con la completezza:

\begin{myteo}[Completezza{\cite[Proposizione 4.4.2]{ambrosio2000selected}}]
  Se $(\Omega,d)$ è completo allora $\pa{C(\Omega),d_H}$ è completo.
\end{myteo}
\begin{proof}
  Sia $\pa{C_n}_{n\in \mathbb{N}} \subseteq C(\Omega)$ una successione
  di Cauchy rispetto a $d_H$, allora esiste $\pa{N_k}_{k\in
    \mathbb{N}}$ crescete tale che 
  \[ \forall n,m \ge N_k\;\; d_H(C_n,C_M) < 2^{-k} \] Scegliamo
  $x_1\in C_{N_1}$, siccome $d_H(C_{N_1},C_{N_2}) < \sfrac{1}{2}
  \Rightarrow d_{C_{N_2}}(x_1) < \sfrac{1}{2}$ allora esiste $x_2\in
  C_{N_2}$ tale che $d(x_1,x_2) < \sfrac{1}{2}$. Induttivamente
  possiamo scegliere una successione $\pa{x_k}_{k\in \mathbb{N}}$ tale
  che $d(x_k,d_{k+1})<2^{-k}$ che è quindi di Cauchy e, per
  completezza di $\Omega$, converge ad un qualche $\bar x\in \Omega$.

  Definiamo ora 
  \[ D_k:= \obar{ \bigcup_{j \ge k} C_{N_j}} \]
  $\forall j \ge k$ si ha $x_j\in D_k$ e quindi, siccome $D_k$ è
  chiuso, $\forall k\; x\in D_k$.

  Sia $C:=\bigcap _k D_k$, questo insieme è chiuso (perché
  intersezione di chiusi) e non vuoto (perché $\bar x\in
  C$). Dimostriamo che $C$ è il limite cercato dando una maggiorazione
  di $d_H(C,C_{N_k})$.

  \[ x\in C \Rightarrow x \in D_k \Rightarrow d_{C_{N_k}}(x) \le
  \frac{1}{2^k} \]
  Dove nell'ultima implicazione usiamo il fatto che $\forall j \ge k
  \; d_H(C_{N_k},C_{N_j}) < \frac{1}{2}$ ottenendo la disuguaglianza
  $\forall x \in \bigcup_{j \ge k} C_{N_j}$, ma per la triangolare di
  $d_{C_k}$ questa disuguaglianza vale passando alla chiusura.
  
  D'altra parte $\forall j\ge k$, sempre per $d_H(C_{N_j},C_{N_k}) <
  \frac{1}{2^k}$
  \[ \forall x \in C_{C_{N_k}}\; d_{C_{N_j}}(x) < \frac{1}{2^k}
  \Rightarrow d_{D_{j}}(x) < \frac{1}{2^k} \]
  Mettendo insieme le due disuguaglianze si ottiene
  \[ d_H(C_{N_k},C) < \frac{1}{2^k} \]
  
  Ma allora $\forall k \in \mathbb{N}$ si ha $\forall n \ge N_k$
  \[ d_H(C_n,C) \le d_H(C_n,C_{N_k}) + d_H(C_{N_k},C) \le
  \frac{1}{2^k} + \frac{1}{2^k} = \frac{1}{2^{k-1}} \]
  Da cui la tesi per l'arbitrarietà di $k$
\end{proof}

Diamo un risultato di compattezza:
\begin{myteo}[Blaschke{\cite[Teorema 4.4.6]{ambrosio2000selected}}]
  Se $\Omega$ è compatto allora $C(\Omega)$ è compatto nella metrica
  di Hausdorff
\end{myteo}
\begin{proof}
  Siccome $\Omega$ è compatto allora è completo e totalmente limitato,
  se dimostriamo che anche $C(\Omega)$ è totalmente limitato abbiamo
  la tesi perché il teorema precedente ci da la completezza di
  $C(\Omega)$.

  Dato $\varepsilon >0$ sia $F\subseteq E$ insieme finito dei centri di
  una $\varepsilon$-rete che ricopre $E$. Vogliamo dimostrare che
  $\mathcal{F}:= \mathcal{P}(F)$ è l'insieme dei centri di una
  $\varepsilon$-rete finita che ricopre $C(\Omega)$ secondo $d_H$.

  Sia $C\in C(\Omega)$, siccome è chiuso è anche compatto. Considero
  le palle aperte di centro $F\cap C$ e raggio $\varepsilon$, questo è
  un ricoprimento di $C$ e ne estraggo quindi un sottoricoprimento
  finito di centri $D=\set{d_1,...,d_n} \in \mathcal{F}$. Per
  costruzione del sottoricoprimento si ha $C \subseteq D +
  \bar B_\varepsilon$, d'altra parte $D \subseteq C$. Quindi
  \[ \forall C \in C(\Omega)\; \exists D \in \mathcal{F}\text{ t.c. }
  d_H(C,D) < \varepsilon \]
  Cioè abbiamo trovato una $\varepsilon$-rete in $C(\Omega)$ da cui la
  totale limitatezza.
\end{proof}

La compattezza di $C(\Omega)$ è molto comoda, infatti ci dice che
tutte le funzioni semicontinue inferiormente ammettono minimo.

Mostro, per esempio, che il numero di componenti connesse è una
funzione s.c.i. in $C(\Omega)$, inzio con un lemma.

\begin{mylem}
  Dati $A,B \subseteq \Omega$ chiusi con $A$ compatto e supponiamo che
  \[ \inf _{x\in A} d_B(x) = 0 \]
  Allora $A\cup B$ è connesso
\end{mylem}
\begin{proof}
  Sia $\pa{x_n}_{n\in \mathbb{N}} \subseteq A$ tale che $\forall n\;
  d_B(x_n) < \frac{1}{n}$. Siccome $A$ è compatto si ha che, a meno di
  passare a sottosuccessioni, $x_n \to \bar x \in A$. Si verifica
  facilmente che $d_B(x) = 0$. Ma $B$ è chiuso, quindi $x\in B$ da cui 
  \[ A \cap B \supseteq \set{x} \neq \emptyset \]
  Essendo $A,B$ connessi si ha la tesi.
\end{proof}
\begin{mycor}
  Due componenti connesse distinte chiuse e compatte hanno distanza di
  Hausdorff non nulla.
\end{mycor}

\begin{mypro}
  La funzione $f:\; C(\Omega) \rightarrow \mathbb{N} \cup \set{+\infty}$
  che ad un chiuso associa il numero delle sue componenti connesse è
  semicontinua inferiormente
\end{mypro}
\begin{proof}
  Dobbiamo dimostrare che la controimmagine di $\left(n-1,
    +\infty\right]$ è continua qualunque sia $n>0$, questo equivale a
  dimostrare che la controimmagine di $\bra{n,+\infty}$ è aperta.

  Chiamiamo $I = f^{-1}\pa{\bra{n,+\infty}}$.

  Sia quindi $A \in I$, vogliamo dimostrare che esiste un intorno
  aperto di $A$ in $I$.

  Se troviamo $\varepsilon$ tale che $A + \bar B_{\varepsilon} \in I$
  allora ogni $D \subseteq A + \bar B_{\varepsilon}$ avrà almeno $n$
  componenti connesse, quindi anche questo varrà anche per $\set{D \in
    C(\Omega):\; d_H(A,D) < \varepsilon}$ per la relazione
  \[ \set{D \in C(\Omega):\; d_H(A,D) < \varepsilon} \subseteq \set{D
    \in C(\Omega):\; D \subseteq A + \bar B_{\varepsilon}} \]

  Separiamo le componenti connesse in $n$ gruppi includendole in $n$
  aperti in $\Omega$ connessi $A_1,A_2,...,A_n$ tali che le loro
  chiusure non si intersechino a due a due. Iniziamo prendendo un
  aperto che contenga tutte le componenti connesse, per esempio
  $\Omega$, se $n=1$ abbiamo finito, altrimenti (per la definizione di
  connessione) possiamo dividere questo aperto in due aperti con le
  proprietà richieste. Iteriamo questa costruzione dividendo ogni
  volta un aperto che contiene più di una componente connessa
  fermandoci quando otteniamo $n$ insiemi. Possiamo arrivare ad
  otterne $n$ perché, per ipotesi, $A$ ha almeno $n$ componenti
  connesse. Inoltre, per costruzione, $A \subseteq A_1 \cup A_2 \cup
  ... \cup A_n$.

  Per il lemma precedente le distanze di Hausdorff reciproche di $A_1,
  ..., A_n$ sono non nulle, sia $\delta$ il minimo di queste distanze
  e scegliamo $\varepsilon = \sfrac{\delta}{3}$. Ma allora questo è il
  $\varepsilon$ cercato, infatti $\pa{A_1\cup ... \cup A_n} + \bar B
  _\varepsilon$ ha ancora $n$ componenti connesse e di conseguenza le
  ha anche $A + \bar B_{\varepsilon}$ per la relazione
  \[ A + \bar B_{\varepsilon} \subseteq \pa{A_1\cup ... \cup A_n} +
  \bar B_\varepsilon\]
\end{proof}
\begin{mynot}
  Secondo me questa costruzione non funziona davvero, almeno non
  così. Bisogna usare da qualche parte l'ipotesi di compattezza di
  $\Omega$.

  Ma perché ho detto che posso trovare due chiusi disgiunti che
  separano l'insieme? TODO.
\end{mynot}
\begin{mycor}
  Limite di insiemi connessi è connesso.
\end{mycor}

TODO: l'area invece non è così.

\section{Geodetiche}

Sia ancora $(M,d)$ uno spazio metrico dove vogliamo definire le
geodetiche, per farlo inziiamo definendo la lunghezza di una curva
$\gamma :\; \bra{a,b} \to M$
\begin{mydef}[Lunghezza di una curva]
  \[ \len^d \gamma := \sup _{\mathcal{P}_{fin}(\bra{a,b}) \ni T =
    \set{t_1 \le t_2 \le ... \le t_n}} \sum_{i=1}^n d\pa{
    \gamma\pa{t_{i-1}}, \gamma\pa{t_i}} \]
\end{mydef}

Chiamiamo $\Gamma (x,y) = \set{\gamma:\; \bra{a,b} \to M \mid
  \gamma(a) = x, \gamma(b) = y}$

\begin{mydef}[Distanza geodetica indotta]
  \[ d^g (x,y) := \inf _{\gamma \in \Gamma(x,y)} \len^d \gamma \]
\end{mydef}

\begin{myoss}
  Dalla triangolare otteniamo che 
  \[ \forall \gamma \in \Gamma(x,y) \; \len^d \gamma \ge d(x,y) \]
  Passando all'$\inf$ ottentiamo quindi
  \[ d^g(x,y) \ge d(x,y) \]
  Comunque scegliamo $x,y \in M$.
\end{myoss}

In generale non vale l'uguaglianza, e cambia anche la
topologia. Mostro che un compatto opportuno $M \subseteq \mathbb{R}^2$
con la metrica euclidea indotta non è compatto nella topologia delle
geodetiche.

\begin{myes}[{\cite[Esempio 2.1]{DuciMennucci2007}}]
  Sia $E = \bra{0,1} \times \pa{ \set{0} \cup \set{ \frac{1}{n} \mid n
      > 0} }$ e $\psi(\rho,\theta) = \rho
  \pa{\cos(\theta),\sin(\theta)}$. Considero quindi $M = \psi(E)$.

  $M$ è unione di segmenti di lunghezza $1$, passanti per l'origine
  con inclinazione decrescente che tendono al segmento orrizzontale
  (accumolandosi). %TODO: disegno

  $M$ è compatto nella metrica euclidea, nella metrica indotta dalle
  geodetiche, però, $M$ non è più compatto, infatti i punti $x_n =
  \psi(1,\frac{1}{n})$ non posso ammettere una sottosuccessione
  convergente essendo, per ogni $n\neq m$, $d^g(x_n,y_m) = 2$.
\end{myes}

Questo non esclude che in alcuni casi $d = d^g$, per esempio
\begin{mypro}
  $\pa{d^g}^g = d^g$
\end{mypro}
\begin{proof}
  Basta dimostrare che $\forall x,y \in M$ si ha $\pa{d^g}^g(x,y) \le
  d^g(x,y)$.

  Sia $\tilde\gamma \in \Gamma(x,y)$ tale che $\len ^d \tilde\gamma <
  d^g(x,y) + \varepsilon$, voglio stimare la sua lunghezza in $d^g$,
  prendo quindi $\set{t_0,t_1,...,t_n} \subseteq \bra{a,b}$ tale che
  \[ \sum _{i=1} ^n d^g(\tilde\gamma(t_{i-1}),\tilde\gamma(t_i)) \ge
  \len ^{d^g} \tilde\gamma - \varepsilon \] Per la relazione $d\le
  d^g$ ho:
  \[ \len ^{d^g} \tilde\gamma \le \varepsilon + \sum _{i=1} ^n
  d^g(\tilde\gamma(t_{i-1}),\tilde\gamma(t_i)) \le \varepsilon + \sum
  _{i=1} ^n d(\tilde\gamma(t_{i-1}),\tilde\gamma(t_i)) \le \varepsilon
  + \len ^d \tilde\gamma < 2 \varepsilon + d^g(x,y) \]

  Quindi
  \[ \pa{d^g}^g (x,y) = \inf _{\gamma \in \Gamma(x,y)} \len ^{d^g}
  \gamma \le \len ^{d^g} \tilde\gamma \le 2 \varepsilon + d^g(x,y) \]
  Mandando $\varepsilon \to 0$ si ha la tesi.
\end{proof}


\newpage

\bibliographystyle{alpha}
\bibliography{Selected_Topics_on_Analysis_in_Metric_Sp,Banach-like_metrics_and_metrics_of_compact_sets}


\newpage

\textbf{What??}

\begin{itemize}
\item Ambrosio-Tilli, definizione 4.4.2 (distanza di hausdorff): tutte le
  distanze vengono troncate a $1$ ($d'_H = \min\set{1,d_H}$). Why??
\end{itemize}


\newpage

Cose possibili da fare:

\begin{itemize}
\item Vedere quando, nelle definizioni di $d_H$ gli $\inf$ e $\sup$ si
  possono trasformare in $\min$ e $\max$.
\end{itemize}



\newpage

Trovare le ipotesi giuste per:
\begin{itemize}
\item ???? $d_A$ è Frechet differenziabile q.o. e $\abs{\nabla d_A}
  \le 1$
\end{itemize}


\newpage
Ipotesi: $\mathbb{R}^N$

I chiusi e limitati sono compatti, quindi riesco a trasformare gli
$\inf$ in $\min$ mettendomi in una palla $B(y,2*d+\varepsilon)$ quando
lavoro con chiusi


\newpage
Cose saltate che potrebbero essere inserite
\begin{itemize}
\item skeleton
  \begin{itemize}
  \item caratterizzazione coi punti dove non esiste il gradiente di
    $d_A$
  \end{itemize}
\item Convergenza di kuratowski (ambrosio tilli p.77) è implicata
  dalla Hausdorff ed è equivalente in compatti
\end{itemize}


\end{document}

