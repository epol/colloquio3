\documentclass[a4paper,10pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{xfrac}
\usepackage[all]{xy}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{fullpage}
\usepackage{hyperref}
\usepackage[utf8x]{inputenc}
\usepackage[italian]{babel}

\usepackage{pdftricks}
\begin{psinputs}
   \usepackage{pstricks}
   \usepackage{multido}
\end{psinputs}

\usepackage{ulem}

\setlength{\parindent}{0in}

\newcounter{counter1}

\theoremstyle{plain}
\newtheorem{myteo}[counter1]{Teorema}
\newtheorem{mylem}[counter1]{Lemma}
\newtheorem{mypro}[counter1]{Proposizione}
\newtheorem{mycor}[counter1]{Corollario}
\newtheorem*{myteo*}{Teorema}
\newtheorem*{mylem*}{Lemma}
\newtheorem*{mypro*}{Proposizione}
\newtheorem*{mycor*}{Corollario}

\theoremstyle{definition}
\newtheorem{mydef}[counter1]{Definizione}
\newtheorem{myes}[counter1]{Esempio}
\newtheorem{myex}[counter1]{Esercizio}
\newtheorem*{mydef*}{Definizione}
\newtheorem*{myes*}{Esempio}
\newtheorem*{myex*}{Esercizio}

\theoremstyle{remark}
\newtheorem{mynot}[counter1]{Nota}
\newtheorem{myoss}[counter1]{Osservazione}
\newtheorem*{mynot*}{Nota}
\newtheorem*{myoss*}{Osservazione}

\newcommand{\obar}[1]{\overline{#1}}
\newcommand{\ubar}[1]{\underline{#1}}

\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\pa}[1]{\left(#1\right)}
\newcommand{\ang}[1]{\left<#1\right>}
\newcommand{\bra}[1]{\left[#1\right]}
\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\norm}[1]{\left\|#1\right\|}

\newcommand{\pfrac}[2]{\pa{\frac{#1}{#2}}}
\newcommand{\bfrac}[2]{\bra{\frac{#1}{#2}}}
\newcommand{\psfrac}[2]{\pa{\sfrac{#1}{#2}}}
\newcommand{\bsfrac}[2]{\bra{\sfrac{#1}{#2}}}

\newcommand{\der}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\pder}[2]{\pfrac{\partial #1}{\partial #2}}
\newcommand{\sder}[2]{\sfrac{\partial #1}{\partial #2}}
\newcommand{\psder}[2]{\psfrac{\partial #1}{\partial #2}}

\newcommand{\intl}{\int \limits}

\DeclareMathOperator{\de}{d}
\DeclareMathOperator{\id}{Id}
\DeclareMathOperator{\len}{len}


\title{Colloquio 3 - appunti1}
\author{Enrico Polesel}
\date{\today}

\begin{document}
\maketitle

\section{Distanza di Hausorff}

Ipotesi: $(M,d)$ spazio metrico completo\footnote{TODO: decidere se
  togliere l'ipotesi di completezza e metterla in tutti gli enunciati
  che la richiedono}

Ipotesi: $\Omega \subseteq M$ chiuso

\begin{mydef}[Distanza di un punto da un insieme]
\[  d_A (x) := \inf _{y \in A} d(x,y) \] 
\end{mydef}

\textbf{Idea:} forme $\leftrightarrow$ sottoinsiemi chiusi
$\leftrightarrow$ funzioni $d_A$

\begin{mydef}[Spazio di forme]
  \[ C_d(\Omega) = \set{d_A : A \subseteq \Omega,\; A \neq \emptyset} \]
\end{mydef}

\begin{mypro}[Proprietà della distanza punto-insieme]
  Vale:
  \begin{itemize}
  \item La funzione $x \rightarrow d_A(x)$ è 1-Lipschitz (e quindi
    continua)
  \item $d_{A\cup B}(x) = \min\set{d_A(x),d_B(x)}$
  \item $\set{x:d_A(x) = 0} = \bar A$
  \item $d_A \equiv 0 \Rightarrow $ è denso in $\Omega$
  \item $d_{\bar A} = d_A$
  \item $A\subseteq B \Rightarrow d_A \ge d_B$
  \item $\bar A \subseteq \bar B \Leftrightarrow d_A \ge d_B$
  \item $d_A = d_B \Leftrightarrow \bar A = \bar B$
  \end{itemize}
\end{mypro}
\begin{proof} [Dimostrazione di $\set{x:d_A(x) = 0} = \bar A$]
  \`E ovvio che $x\in \bar A \Rightarrow d_A(x) = 0$ perché 
  \[ \forall \varepsilon > 0\; \exists y \in a \cap B(x,\varepsilon)
  \Rightarrow \forall \varepsilon > 0 \; d_A(x) \le d(x,y) <
  \varepsilon \]

  Sia $x\not\in \bar A$, allora esiste $\varepsilon>0$ tale che
  $B(x,\varepsilon) \cap A = \emptyset$. Allora $d_A(x) \ge
  \varepsilon$.
\end{proof}

\begin{proof}[Dimostrazione di $\bar A \subseteq \bar B
  \Leftrightarrow d_A \ge d_B$]
  Essendo $d_B \ge 0$ si ha che $d_A = 0 \Rightarrow d_B = 0$. Ma
  questo significa che 
  \[ x \in \bar A \Rightarrow x \in \bar B \]

  Se $\bar A \subseteq \bar B$ assumiamo wlog $A = \bar A, B = \bar B$
  (le funzioni distanza non cambiano passando alla chiusura). Allora
  la disuguaglianza è verificata perché stiamo facendo l'$\inf$ su due
  insiemi contenuti.  
\end{proof}


\begin{mylem}
  Se $A$ è compatto e completo allora l'$\inf$ della definizione di
  $d_A$ è in realtà un $\min$, cioè:
  \[ \forall x \in \Omega \; \exists y \in A \ :\ d(y,x) = d_A(x) \]
\end{mylem}
% \begin{proof}
%   Se $d_A(x) = \delta$ allora esiste $\pa{a_n}_{n\in \mathbb{N}}$ con
%   $a_n \in A$ tale che
%   \[ d(a_n,x) < \delta + \frac{1}{n} \] 
%   Ma, per compattezza, estraiamo una sottosuccessione
%   $\pa{a_{n_k}}_{k\in \mathbb{N}}$ che converge ad un punto in $A$ che
%   chiamiamo $\bar a$.  Allora, scelto $n_k$ tale che $d(a_{n_k},\bar
%   a) < \frac{1}{n}$ e che $n_k > n$ si ha
%   \[ d(x,\bar a) \le d\pa{x,a_{n_k}} + d\pa{a_{n_k}, \bar a} \le
%   \frac{1}{n_k} + \frac{1}{n} \le \frac{2}{n} \]
%   Per $n \to \infty$ si ha $d(x,\bar a) \le \delta$, ma $\bar a \in A$
%   dà la disuguaglianza opposta da cui $\bar a$ è il punto cercato.
% \end{proof}
\begin{proof}
  $d_A$ è una funzione continua su un compatto, quindi ha minimo.
\end{proof}

\begin{mylem}\label{lem:pallechiusecompattemin}
  Se in $M$ le palle chiuse sono compatte, dato $A$ chiuso l'$\inf$
  della definizione di $d_A$ è un minimo.
\end{mylem}
\begin{proof}
  Dato $x\in M$ supponiamo $d_A(x) < \infty$ (altrimenti la tesi è
  ovvia). Allora è evidente che possiamo cercare tale minimo in 
  \[ A \cap \bar B\pa{x,2 d_A(x)} \]
  che è compatto per ipotesi.
\end{proof}

\begin{mynot}
  Se $A$ non è compatto ma è un chiuso allora, in generale, il lemma
  precedente non è verificato. Costriuisco un controesempio in $l^2$
  
  Sia, per $n\in \mathbb{N}$ $a_n$ la successione con $1+\frac{1}{n}$
  all'$n$-esimo posto e $0$ altrove. Sia $A = \set{a_n : n\in
    \mathbb{N}}$. Si pu\`o dimostrare che $A$ \`e chiuso utilizzando
  la propriet\`a $\bar A = \set {d_A = 0}$ oppure, più semplicemente,
  perché contiene tutti i suoi punti di accumulazione.

  Considero l'origine:
  \[ d_A(O) = \inf _{n\in \mathbb{N}} \norm{a_n}_2 = \inf _{n\in
    \mathbb{N}} \pa{1+\frac{1}{n}}^2 = 1 \]
  Però $\forall n\in \mathbb{N}\; d(O,a_n) > 1$ e quindi non si
  raggiunge il minimo per nessun punto.  
\end{mynot}

\begin{mynot}
  In uno spazio vettoriale di dimensione finita il lemma vale
  chiedenso solo che $A$ sia chiuso applicando il lemma
  \ref{lem:pallechiusecompattemin}.
\end{mynot}


\begin{myoss}
  Usare le funzioni $d_A$ per classificare gli insiemi significa
  vederli a meno di chiusure, quindi quozientiamo per
  \[ A \approx B \Leftrightarrow \bar A = \bar B \] 

  È ovvio che possiamo prendere come rappresentate di una classe
  l'\textit{unica} chiusura di ogni insieme, quindi abbiamo
  \[ \sfrac{\set{A \subseteq \Omega}}{\approx} \cong C_s(\omega) := \set{A
    \subseteq \Omega,\ A\text{ chiuso},\; A\neq \emptyset} \]
\end{myoss}
\begin{mypro}
  \[ C_s(\Omega) \cong C_d(\Omega) \]
  \[ A \rightarrow d_A \]
\end{mypro}
\begin{proof}
  La mappa è sicuramente ben definita e surgettiva per come è definito
  $C_d(\Omega)$. Per l'iniettività ci basta osservare che se $d_A =
  d_B$ con $A,B \in C_s(\Omega)$ allora $\bar A = \bar B$, ma $A$ e $B$
  sono chiusi da cui la tesi.
\end{proof}



\begin{mydef}[Distanza di Hausdorff]
  Dati due insiemi $A,C \subseteq \Omega$ definiamo
%  \[ d_H (A,C) = \norm{ d_A - d_C } _\infty = \sup _{x\in \Omega}
%  \set {d_A(x) - d_C(x)}\]
%
%  Anzi, la definisco come:
  \[ d_H(A,C) = \max \set{\sup _{x\in A} d_C (x) , \sup _{x\in C} d_A
    (x) } \]
\end{mydef}

In seguito dimostrerò che $d_H$ è una funzione distanza

Notazione: definiamo (con un abuso di linguaggio):
\[ A + \bar B_\varepsilon := \set{ x \in \Omega : \exists y \in A :
  d(x,y) \le \varepsilon }\]
Questa uguaglianza vale, infatti, in $R^N$ e, più in generale, in
spazi vettoriali reali.


\begin{mypro}
  Se $A, C$ sono \sout{compatti} \sout{chiusi} le seguenti definizioni
  sono equivalenti
  \begin{enumerate}
  \item $ d_H (A,C) = \norm{ d_A - d_C } _\infty = \sup _{x\in \Omega}
    \set {d_A(x) - d_C(x)}$
  \item $d_H(A,C) = \max \set{\sup _{x\in A} d_C (x) , \sup _{x\in C}
      d_A (x) }$
  \item $d_H (A,C) = \inf \set{\delta : A \subseteq C + \bar B
    _\delta \wedge C \subseteq A + \bar B_\delta} = \max \set{\inf
    \set{\delta : A \subseteq C + \bar B _\delta }, \inf \set{\delta : C
      \subseteq A + \bar B _\delta }}  $
  \end{enumerate}
\end{mypro}

\begin{proof}
  \textbf{$2 \sim 3$} Basta dimostrare che $\sup _{x\in A} d_C(x) =
  \inf \set{ \delta : A \subseteq C + \bar B _{\delta}}$.

  Se $\sup _{x\in A} d_C(x) = \alpha$ allora
  \[ \forall x \in A, \; d_C (x) \le \alpha \Rightarrow \pa{\forall
    \varepsilon > 0 \exists y \in C \mid d(x,y) < \alpha +
    \varepsilon} \Rightarrow \pa{\forall \varepsilon > 0 \; x
    \in C + \bar B _{\alpha + \varepsilon}}\]
  Valendo questa relazione $\forall x \in A$ si ha
  \[ \pa{\forall \varepsilon > 0 \; A \subseteq C + \bar B _{\alpha +
      \varepsilon}} \Rightarrow \inf \set{ \delta : A \subseteq C +
    \bar B _{\delta}} \le \alpha \]

  D'altra parte se $\varepsilon > 0$ allora $\exists x \in A$ tale che
  $d_C(x) > \alpha - \varepsilon$. Allora
  \[ \alpha - \varepsilon < \inf_{y\in C}\set{d(x,y)} \Rightarrow
  \forall y \in C\; d(x,y) > \alpha - \varepsilon \Rightarrow x\not\in
  C + \bar B_{\alpha - \varepsilon} \Rightarrow \inf \set{ \delta : A
    \subseteq C + \bar B _{\delta}} \ge \alpha - \varepsilon\]
  Per $\varepsilon \rightarrow 0$ si ha quindi l'altra disuguaglianza
  ottenendo la tesi.

  \textbf{$1\sim 2$}
  Sia $\max \set{\sup _{x\in A} d_C (x) , \sup _{x\in C} d_A (x) } =
  \delta$.
  
  Voglio valutare $\sup_{x\in \Omega} \abs{d_A(x)-d_C(x)}$.

  Primo caso: $x\in A$. Allora
  \[ d_A(x) = 0 \Rightarrow \abs{d_A(x)-d_C(x)} = d_C(x) \le \sup
  _{x\in A} d_C (x) \le \delta \]
  Secondo caso: $x\in C$, in modo analogo al caso precedente otteniamo
  $\abs{d_A(x)-d_C(x)} \le \delta$.
  
  Caso generale: sia $x\in \Omega$, supponiamo wlog $d_A(x) \ge d_C(x)$
  (l'altro caso vale per simmetria). Quindi$\abs{d_A(x)-d_C(x)} =
  d_A(x)-d_C(x)$. Scegliendo $y \in C$ tale che $d(x,y) < d_C(x) +
  \varepsilon$ (con $\varepsilon > 0$) si ha
  \[ d_A(x)-d_C(x) \le d_A(y) + d(x,y) - d_C(x) < d_A(y) + d_C(x) +
  \varepsilon -d_C(x) = d_A(y) + \varepsilon\]
  Per $\varepsilon \rightarrow 0$ si ha $d_A(x) - d_C(x) \le d_A(x)
  \le \delta$.

  Dimostriamo ora che il $\sup_{x\in \Omega} \abs{d_A(x)-d_C(x)} \ge
  \delta$. Per farlo supponiamo wlog 
  \[ \delta = \max \set{\sup _{x\in A} d_C (x) , \sup _{x\in C} d_A
    (x) } = \sup _{x\in A} d_C (x) \] 
  (nell'altro caso si conclude con un ragionamento analogo).

  Quindi esiste $\pa{x_n}_{n\in\mathbb{N}}$, $x_n\in A$ tale che
  $d_C(x_n) > \delta - \frac{1}{n}$. Ma allora
  \[ \abs{d_A(x_n) - d_C(x_n)} = d_C(x_n) > \delta - \frac{1}{n} \]
  Facendo tendere $n$ all'infinito si ha la disuguaglianza cercata da
  cui la tesi.
\end{proof}

\begin{myoss}
  La distanza di Hausorff è definita, in realtà, su $\set{A \subseteq
    \Omega}$, su questo spazio, però, non è una distanza perché non
  distingue tra un insieme e la sua chiusura, quozientando per la
  relazione $\cong$ otteniamo una distanza in $C_s(\Omega)$.
\end{myoss}
\begin{proof}
  È ovvio che $d_H \ge 0$ e che $d_H(A,C) = d_H(C,A)$.

  Dimostriamo che $d_H(A,C) = 0 \Leftrightarrow A = C$: questo vale se
  $\norm{d_A - d_C}_\infty = 0$ che equivale a dire $d_A = d_C$ e
  quindi $\bar A = \bar C$ da cui un'implicazione perché $A,C$ sono
  chiusi, l'altra implicazione è invece ovvia.

  Per la triangolare osserviamo che, dati $A,B,C \subseteq \Omega$
  chiusi si ha
  \[ \abs{d_A(x) - d_C(x)} \le \abs{d_A(x) - d_B(x)} + \abs{d_B(x) -
    d_C(x)} \le d_H(A,B) + d_H(B,C) \]
  Da cui la tesi passando all'estremo superiore per $x\in \Omega$.
\end{proof}

\begin{mycor}
  La relazione $C_s(\Omega) \cong C_d(\Omega)$ è un'isometria usando su
  $C_d(\Omega)$ la distanza di Hausdorff su $C_s(\Omega)$ e la norma
  infinito su $C_d(\Omega)$
\end{mycor}

\begin{myoss}
  Per come l'abbiamo definita, la distanza di Hausdorff ha valori in
  $\mathbb{R}_0^+ \cup \set{+\infty}$.

  Se questo è un problema possiamo aggirarlo in due modi:
  \begin{itemize}
  \item Chiedendo $\Omega$ limitato 
  \item Prendendo come distanza fra $A$ e $C$ il valore $\min\set{ d_H
      (A,C) , M}$ con $M >0$
  \end{itemize}
\end{myoss}

Vogliamo studiare ora le propriet\`a di $C_s(\Omega) = C_d(\Omega)$ come
spazio metrico, iniziamo con la completezza:

\begin{myteo}[Completezza{\cite[Proposizione 4.4.2]{ambrosio2000selected}}]
  Se $(\Omega,d)$ è completo allora $\pa{C_s(\Omega),d_H}$ è completo.
\end{myteo}
\begin{proof}
  Sia $\pa{C_n}_{n\in \mathbb{N}} \subseteq C_s(\Omega)$ una successione
  di Cauchy rispetto a $d_H$, allora esiste $\pa{N_k}_{k\in
    \mathbb{N}}$ crescete tale che 
  \[ \forall n,m \ge N_k\;\; d_H(C_n,C_m) < 2^{-k} \] Scegliamo
  $x_1\in C_{N_1}$, siccome $d_H(C_{N_1},C_{N_2}) < \sfrac{1}{2}
  \Rightarrow d_{C_{N_2}}(x_1) < \sfrac{1}{2}$ allora esiste $x_2\in
  C_{N_2}$ tale che $d(x_1,x_2) < \sfrac{1}{2}$. Induttivamente
  possiamo scegliere una successione $\pa{x_k}_{k\in \mathbb{N}}$ tale
  che $d(x_k,d_{k+1})<2^{-k}$ che è quindi di Cauchy e, per
  completezza di $\Omega$, converge ad un qualche $\bar x\in \Omega$.

  Definiamo ora 
  \[ D_k:= \obar{ \bigcup_{j \ge k} C_{N_j}} \]
  $\forall j \ge k$ si ha $x_j\in D_k$ e quindi, siccome $D_k$ è
  chiuso, $\forall k\;\; \bar x\in D_k$.

  Sia $C:=\bigcap _k D_k$, questo insieme è chiuso (perché
  intersezione di chiusi) e non vuoto (perché $\bar x\in
  C$). Dimostriamo che $C$ è il limite cercato dando una maggiorazione
  di $d_H(C,C_{N_k})$.

  \[ x\in C \Rightarrow x \in D_k \Rightarrow d_{C_{N_k}}(x) \le
  \frac{1}{2^k} \]
  Dove nell'ultima implicazione usiamo il fatto che $\forall j \ge k
  \; d_H(C_{N_k},C_{N_j}) < \frac{1}{2}$ ottenendo la disuguaglianza
  $\forall x \in \bigcup_{j \ge k} C_{N_j}$, ma per la triangolare di
  $d_{C_k}$ questa disuguaglianza vale passando alla chiusura.
  
  D'altra parte $\forall j\ge k$, sempre per $d_H(C_{N_j},C_{N_k}) <
  \frac{1}{2^k}$
  \[ \forall x \in C_{C_{N_k}}\; d_{C_{N_j}}(x) < \frac{1}{2^k}
  \Rightarrow d_{D_{j}}(x) < \frac{1}{2^k} \]
  Mettendo insieme le due disuguaglianze si ottiene
  \[ d_H(C_{N_k},C) < \frac{1}{2^k} \]
  
  Ma allora $\forall k \in \mathbb{N}$ si ha $\forall n \ge N_k$
  \[ d_H(C_n,C) \le d_H(C_n,C_{N_k}) + d_H(C_{N_k},C) \le
  \frac{1}{2^k} + \frac{1}{2^k} = \frac{1}{2^{k-1}} \]
  Da cui la tesi per l'arbitrarietà di $k$
\end{proof}

Diamo un risultato di compattezza:
\begin{myteo}[Blaschke{\cite[Teorema 4.4.6]{ambrosio2000selected}}]
  Se $\Omega$ è compatto allora $C_s(\Omega)$ è compatto nella metrica
  di Hausdorff
\end{myteo}
\begin{proof}
  Siccome $\Omega$ è compatto allora è completo e totalmente limitato,
  se dimostriamo che anche $C_s(\Omega)$ è totalmente limitato abbiamo
  la tesi perché il teorema precedente ci da la completezza di
  $C_s(\Omega)$.

  Dato $\varepsilon >0$ sia $F\subseteq \Omega$ insieme finito dei centri di
  una $\varepsilon$-rete che ricopre $\Omega$. Vogliamo dimostrare che
  $\mathcal{F}:= \mathcal{P}(F)$ è l'insieme dei centri di una
  $\varepsilon$-rete finita che ricopre $C_s(\Omega)$ secondo $d_H$.

  Sia $C\in C_s(\Omega)$, siccome è chiuso è anche compatto. Considero
  le palle aperte di centro $F\cap C$ e raggio $\varepsilon$, questo è
  un ricoprimento di $C$ e ne estraggo quindi un sottoricoprimento
  finito di centri $D=\set{d_1,...,d_n} \in \mathcal{F}$. Per
  costruzione del sottoricoprimento si ha $C \subseteq D +
  \bar B_\varepsilon$, d'altra parte $D \subseteq C$. Quindi
  \[ \forall C \in C_s(\Omega)\; \exists D \in \mathcal{F}\text{ t.c. }
  d_H(C,D) < \varepsilon \]
  Cioè abbiamo trovato una $\varepsilon$-rete in $C_s(\Omega)$ da cui la
  totale limitatezza.
\end{proof}

La compattezza di $C_s(\Omega)$ è molto comoda, infatti ci dice che
tutte le funzioni semicontinue inferiormente ammettono minimo.

Mostro, per esempio, che il numero di componenti connesse è una
funzione s.c.i. in $C_s(\Omega)$, inzio con un lemma.

\begin{mylem}
  Dati $A,B \subseteq \Omega$ chiusi con almeno uno dei due compatto e
  $A \cap B \neq \emptyset$ allora
  \[ \inf _{x\in A} d_B(x) = \inf _{(x,y) \in A\times B} d(x,y) = \inf
  _{y\in B} d_A(y) >0 \]
\end{mylem}
\begin{proof}
  Sia $A$ compatto, allora $x \to d_B(x)$ ha minimo in $A$, sia $\bar
  x \in A$ tale minimo. Se $d_B(\bar x) = 0$ allora $\bar x \in \bar B = B$
  contro l'ipotesi $A \cap B = \emptyset$
\end{proof}

Sia $K(\Omega) = \set{K\subseteq \Omega :\; K \text{ compatto}}$.

\begin{mypro}
  La funzione $f:\; K(\Omega) \rightarrow \mathbb{N} \cup \set{+\infty}$
  che ad un compatto associa il numero delle sue componenti connesse è
  semicontinua inferiormente
\end{mypro}
\begin{proof}
  Dobbiamo dimostrare che la controimmagine di $\left(n-1,
    +\infty\right]$ è continua qualunque sia $n>0$, questo equivale a
  dimostrare che la controimmagine di $\bra{n,+\infty}$ è aperta.

  Chiamiamo $I = f^{-1}\pa{\bra{n,+\infty}}$.

  Sia quindi $A \in I$, vogliamo dimostrare che esiste un intorno
  aperto di $A$ in $I$.

  Se troviamo $\varepsilon$ tale che $A + \bar B_{\varepsilon} \in I$
  allora ogni $D \subseteq A + \bar B_{\varepsilon}$ avrà almeno $n$
  componenti connesse, quindi anche questo varrà anche per $\set{D \in
    C(\Omega):\; d_H(A,D) < \varepsilon}$ per la relazione
  \[ \set{D \in C(\Omega):\; d_H(A,D) < \varepsilon} \subseteq \set{D
    \in C(\Omega):\; D \subseteq A + \bar B_{\varepsilon}} \]

  Separiamo le componenti connesse in $n$ gruppi includendole in $n$
  chiusi $A_1,A_2,...,A_n$ (chiusi nella topologia di $\Omega$) tali
  che non si intersechino a due a due. Iniziamo prendendo un chiuso
  che contenga tutte le componenti connesse, cioè $A$, se $n=1$
  abbiamo finito, altrimenti (per la definizione di connessione)
  possiamo dividere questo chiuso in due chiusi con le proprietà
  richieste, infatti esistono $\tilde A_1, \tilde A_2$ aperti e chiusi
  nella topologia indotta in $A$ tali che $A = \tilde A_1 \cup \tilde
  A_2$ e che $\tilde A_1 \cap \tilde A_2 = \emptyset$, ma siccome $A$
  è chiuso in $\Omega$ si ha che $\tilde A_1, \tilde A_2$ sono chiusi
  nella topologia di $\Omega$.

  Iteriamo questa costruzione dividendo ogni volta un chiuso che
  contiene più di una componente connessa fermandoci quando otteniamo
  $n$ insiemi. Possiamo arrivare ad otterne $n$ perché, per ipotesi,
  $A$ ha almeno $n$ componenti connesse. Inoltre, per costruzione, $A
  = A_1 \cup A_2 \cup ... \cup A_n$.

  Avendo $A_1,A_2,..., A_n \subseteq A$ chiusi ed essendo $A$ compatto
  per ipotesi allora anche gli $A_1, ..., A_n$ sono compatti e quindi
  per il lemma precedente le distanze di Hausdorff reciproche di $A_1,
  ..., A_n$ sono non nulle, sia $\delta$ il minimo di queste distanze
  e scegliamo $\varepsilon = \sfrac{\delta}{3}$. Ma allora questo è il
  $\varepsilon$ cercato, infatti $\pa{A_1\cup ... \cup A_n} + \bar B
  _\varepsilon$ ha ancora almeno $n$ componenti connesse e di
  conseguenza le ha anche $A + \bar B_{\varepsilon}$ per la relazione
  \[ A + \bar B_{\varepsilon} = \pa{A_1\cup ... \cup A_n} + \bar
  B_\varepsilon\]
\end{proof}
\begin{mycor}
  Limite di insiemi connessi è connesso.
\end{mycor}

TODO: per il chiusi non vale, esempio iperboli

TODO: l'area invece non è così.

\section{Geodetiche}

Sia ancora $(M,d)$ uno spazio metrico dove vogliamo definire le
geodetiche, per farlo inziamo definendo la lunghezza di una curva
$\gamma :\; \bra{a,b} \to M$
\begin{mydef}[Lunghezza di una curva]
  \[ \len^d \gamma := \sup _{\mathcal{P}_{fin}(\bra{a,b}) \ni T =
    \set{t_1 \le t_2 \le ... \le t_n}} \sum_{i=1}^n d\pa{
    \gamma\pa{t_{i-1}}, \gamma\pa{t_i}} \]
\end{mydef}

Chiamiamo $\Gamma (x,y) = \set{\gamma:\; \bra{a,b} \to M \mid
  \gamma(a) = x, \gamma(b) = y,\; \gamma \text{ continua}}$

\begin{mydef}[Distanza geodetica indotta]
  \[ d^g (x,y) := \inf _{\gamma \in \Gamma(x,y)} \len^d \gamma \]
\end{mydef}

\begin{myoss}
  Dalla triangolare otteniamo che 
  \[ \forall \gamma \in \Gamma(x,y) \; \len^d \gamma \ge d(x,y) \]
  Passando all'$\inf$ ottentiamo quindi
  \[ d^g(x,y) \ge d(x,y) \]
  Comunque scegliamo $x,y \in M$.
\end{myoss}

\begin{myoss}
\label{oss:topologiagedoeticafine}
  Da $d^g \ge d$ otteniamo che la topologia generata da $d^g$ è più
  fine di quella generata da $d$ e, di conseguenza, se un insieme è
  compatto con la distanza $d^g$ allora lo è anche con la distanza
  $d$.
\end{myoss}

In generale non vale l'uguaglianza $d = d^g$, e cambia anche la
topologia. Mostro che un compatto opportuno $M \subseteq \mathbb{R}^2$
con la metrica euclidea indotta non è compatto nella topologia delle
geodetiche.

\begin{myes}[{\cite[Esempio 2.1]{DuciMennucci2007}}]
\label{es:topologiageodeticadiversa}
  Sia $E = \bra{0,1} \times \pa{ \set{0} \cup \set{ \frac{1}{n} \mid n
      > 0} }$ e $\psi(\rho,\theta) = \rho
  \pa{\cos(\theta),\sin(\theta)}$. Considero quindi $M = \psi(E)$.

  $M$ è unione di segmenti di lunghezza $1$, passanti per l'origine
  con inclinazione decrescente che tendono al segmento orrizzontale
  (accumolandosi). %TODO: disegno

  \begin{figure}[h]
    \centering
    \begin{pdfpic}
      \begin{pspicture}(0,0)(10,10)
        \psline[linewidth=0.04cm](0.0,0.0)(8.0,0.0)
        \psline[linewidth=0.02cm](0.0,0.0)(4.322418,6.731768)
        \psline[linewidth=0.02cm](0.0,0.0)(7.020660,3.835404)
        \psline[linewidth=0.02cm](0.0,0.0)(7.559656,2.617558)
        \psline[linewidth=0.02cm](0.0,0.0)(7.751299,1.979232)
        \psline[linewidth=0.02cm](0.0,0.0)(7.840533,1.589355)
        \psline[linewidth=0.02cm](0.0,0.0)(7.889146,1.327169)
        \psline[linewidth=0.02cm](0.0,0.0)(7.918506,1.138974)
        \psline[linewidth=0.02cm](0.0,0.0)(7.937581,0.997398)
        \psline[linewidth=0.02cm](0.0,0.0)(7.950668,0.887061)
        \psline[linewidth=0.02cm](0.0,0.0)(7.960033,0.798667)
        \psline[linewidth=0.02cm](0.0,0.0)(7.966965,0.726271)
        \psline[linewidth=0.02cm](0.0,0.0)(7.972238,0.665895)
        \psline[linewidth=0.02cm](0.0,0.0)(7.976343,0.614778)
        \psline[linewidth=0.02cm](0.0,0.0)(7.979601,0.570943)
        \psline[linewidth=0.02cm](0.0,0.0)(7.982229,0.532938)
        \psline[linewidth=0.02cm](0.0,0.0)(7.984380,0.499675)
        \psline[linewidth=0.02cm](0.0,0.0)(7.986163,0.470317)
        \psline[linewidth=0.02cm](0.0,0.0)(7.987657,0.444216)
        \psline[linewidth=0.02cm](0.0,0.0)(7.988922,0.420858)
        \psline[linewidth=0.02cm](0.0,0.0)(7.990002,0.399833)
        \psline[linewidth=0.02cm](0.0,0.0)(7.990931,0.380808)
        \psline[linewidth=0.02cm](0.0,0.0)(7.991737,0.363511)
        \psline[linewidth=0.02cm](0.0,0.0)(7.992440,0.347717)
        \psline[linewidth=0.02cm](0.0,0.0)(7.993057,0.333237)
        \psline[linewidth=0.02cm](0.0,0.0)(7.993601,0.319915)
        \psline[linewidth=0.02cm](0.0,0.0)(7.994084,0.307616)
        \psline[linewidth=0.02cm](0.0,0.0)(7.994514,0.296229)
        \psline[linewidth=0.02cm](0.0,0.0)(7.994899,0.285654)
        \psline[linewidth=0.02cm](0.0,0.0)(7.995244,0.275807)
        \psline[linewidth=0.02cm](0.0,0.0)(7.995556,0.266617)
        \psline[linewidth=0.02cm](0.0,0.0)(7.995838,0.258020)
        \psline[linewidth=0.02cm](0.0,0.0)(7.996094,0.249959)
        \psline[linewidth=0.02cm](0.0,0.0)(7.996327,0.242387)
        \psline[linewidth=0.02cm](0.0,0.0)(7.996540,0.235260)
        \psline[linewidth=0.02cm](0.0,0.0)(7.996735,0.228540)
        \psline[linewidth=0.02cm](0.0,0.0)(7.996914,0.222194)
        \psline[linewidth=0.02cm](0.0,0.0)(7.997078,0.216190)
        \psline[linewidth=0.02cm](0.0,0.0)(7.997230,0.210502)
        \psline[linewidth=0.02cm](0.0,0.0)(7.997370,0.205106)
        \psline[linewidth=0.02cm](0.0,0.0)(7.997500,0.199979)
        \psline[linewidth=0.02cm](0.0,0.0)(7.997621,0.195103)
        \psline[linewidth=0.02cm](0.0,0.0)(7.997733,0.190458)
        \psline[linewidth=0.02cm](0.0,0.0)(7.997837,0.186030)
        \psline[linewidth=0.02cm](0.0,0.0)(7.997934,0.181803)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998025,0.177763)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998110,0.173899)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998189,0.170200)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998264,0.166655)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998334,0.163254)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998400,0.159989)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998462,0.156853)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998521,0.153837)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998576,0.150934)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998628,0.148140)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998678,0.145447)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998725,0.142850)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998769,0.140344)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998811,0.137924)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998851,0.135587)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998889,0.133327)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998925,0.131142)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998959,0.129027)
        \psline[linewidth=0.02cm](0.0,0.0)(7.998992,0.126979)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999023,0.124995)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999053,0.123072)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999082,0.121207)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999109,0.119399)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999135,0.117643)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999160,0.115938)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999184,0.114282)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999207,0.112672)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999228,0.111108)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999249,0.109586)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999270,0.108105)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999289,0.106664)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999307,0.105260)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999325,0.103893)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999343,0.102561)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999359,0.101263)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999375,0.099997)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999390,0.098763)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999405,0.097559)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999419,0.096383)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999433,0.095236)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999446,0.094115)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999459,0.093021)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999472,0.091952)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999483,0.090907)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999495,0.089886)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999506,0.088887)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999517,0.087910)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999527,0.086955)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999538,0.086020)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999547,0.085105)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999557,0.084209)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999566,0.083332)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999575,0.082473)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999584,0.081631)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999592,0.080807)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999600,0.079999)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999608,0.079207)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999616,0.078430)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999623,0.077669)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999630,0.076922)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999637,0.076189)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999644,0.075471)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999651,0.074765)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999657,0.074073)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999663,0.073393)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999669,0.072726)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999675,0.072071)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999681,0.071428)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999687,0.070796)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999692,0.070175)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999698,0.069564)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999703,0.068965)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999708,0.068375)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999713,0.067796)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999718,0.067226)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999722,0.066666)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999727,0.066115)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999731,0.065573)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999736,0.065040)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999740,0.064515)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999744,0.063999)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999748,0.063491)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999752,0.062991)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999756,0.062499)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999760,0.062015)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999763,0.061538)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999767,0.061068)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999770,0.060605)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999774,0.060150)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999777,0.059701)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999781,0.059259)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999784,0.058823)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999787,0.058394)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999790,0.057971)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999793,0.057553)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999796,0.057142)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999799,0.056737)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999802,0.056338)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999804,0.055944)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999807,0.055555)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999810,0.055172)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999812,0.054794)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999815,0.054421)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999817,0.054054)
        \psline[linewidth=0.02cm](0.0,0.0)(7.999820,0.053691)
      \end{pspicture}
    \end{pdfpic}

    \caption{L'insieme dell'esempio \ref{es:topologiageodeticadiversa}}
    \label{fig:topologiageodeticadiversa}
  \end{figure}

  $M$ è compatto nella metrica euclidea, nella metrica indotta dalle
  geodetiche, però, $M$ non è più compatto, infatti i punti $x_n =
  \psi(1,\frac{1}{n})$ non posso ammettere una sottosuccessione
  convergente essendo, per ogni $n\neq m$, $d^g(x_n,y_m) = 2$.
\end{myes}

Questo non esclude che in alcuni casi $d = d^g$, per esempio
\begin{mypro}
  $\pa{d^g}^g = d^g$
\end{mypro}
\begin{proof}
  Basta dimostrare che $\forall x,y \in M$ si ha $\pa{d^g}^g(x,y) \le
  d^g(x,y)$.

  Sia $\tilde\gamma \in \Gamma(x,y)$ tale che $\len ^d \tilde\gamma <
  d^g(x,y) + \varepsilon$, voglio stimare la sua lunghezza in $d^g$,
  prendo quindi $\set{t_0,t_1,...,t_n} \subseteq \bra{a,b}$ tale che
  \[ \sum _{i=1} ^n d^g(\tilde\gamma(t_{i-1}),\tilde\gamma(t_i)) \ge
  \len ^{d^g} \tilde\gamma - \varepsilon \] Per la relazione $d\le
  d^g$ ho:
  \[ \len ^{d^g} \tilde\gamma \le \varepsilon + \sum _{i=1} ^n
  d^g(\tilde\gamma(t_{i-1}),\tilde\gamma(t_i)) \le \varepsilon + \sum
  _{i=1} ^n d(\tilde\gamma(t_{i-1}),\tilde\gamma(t_i)) \le \varepsilon
  + \len ^d \tilde\gamma < 2 \varepsilon + d^g(x,y) \]

  Quindi
  \[ \pa{d^g}^g (x,y) = \inf _{\gamma \in \Gamma(x,y)} \len ^{d^g}
  \gamma \le \len ^{d^g} \tilde\gamma \le 2 \varepsilon + d^g(x,y) \]
  Mandando $\varepsilon \to 0$ si ha la tesi.
\end{proof}

\begin{mydef}[Metrica intrinseca]
  Se la distanza $d$ è tale che $d = d^g$ si dice che $(M,d)$ è una
  metrica intrinseca
\end{mydef}

Per i prossimi risultati userò questi fatti facilemente dimostrabili:
\begin{mylem}
  Data $\gamma:\; \bra{a,b} \to M$ continua si ha $\forall c \in
  \pa{a,b}$
  \[ \len ^d (\gamma_{|\bra{a,c}}) +  \len ^d (\gamma_{|\bra{c,b}}) = 
  \len ^d (\gamma) \] 
\end{mylem}
\begin{mylem}
  Se $\tilde \gamma \in \Gamma (x,y)$ con $\len ^d (\tilde \gamma) = L
  < \infty$ e $\tilde \gamma : \; \bra {a,b} \to M$ allora si può
  riparametrizzare $\tilde \gamma$ in $\gamma : \bra{0,L} \to M$ con la
  proprietà $\len ^d(\gamma_{| \bra{0,t}}) = t$.
\end{mylem}
% \begin{proof}
%   Considero la funzione $t:\bra{a,b} \to \bra{0,L}$ tale che $t(s) =
%   \len ^d (\gamma_{|\bra{0,s}})$ questa funzione è evidentemente
%   crescente e si può verificare che è continua. Quindi posso definire
%   \[ \gamma = \tilde \gamma \circ f^{-1} \]
% \end{proof}
\begin{mylem}
  Con la riparametrizzazione del lemma precedente si ha, presi $0 \le
  t < s \le \len ^d (\gamma)$
  \[ \len ^d (\gamma _{|\bra{t,s}}) = s - t \]
\end{mylem}

E ora un risultato sulla relazione tra intrinsecità di $(M,d)$ e
quella di $\pa{C_s(M),d_H}$
\begin{mypro}
  La metrica di $(M,d)$ è intinseca se e solo se è intrinseca la
  metrica di $(C_s(M),d_H)$
\end{mypro}
\begin{proof}
  Iniziamo dimostrando che $(M,d)$ intrinseca implica $(C_s(M),d_H)$
  inrinseca.

  Siano $A,C \in C_s(M)$ e sia $\mu = d_H(A,C)$ e scegliamo
  $\varepsilon >0$, allora (per la definizione di $d_H$) possiamo dire
  che
  \[ \forall x \in A\; \exists y \in C \mid d(x,y) < \mu +
  \varepsilon \]
  Analogamente per $C$:
  \[ \forall y \in C\; \exists x \in A \mid d(x,y) < \mu +
  \varepsilon \]
  Quindi, detto
  \[ P = \set{(x,y)\in A\times C:\; d(x,y) < \mu + \varepsilon} \]
  Si ha che proiettando $P$ sulle prime componenti troviamo $A$ e
  proiettandolo sulla seconda troviamo $C$ (in generale però $P \neq A
  \times C$).  Siccome $\forall (x,y) \in P\; d^g(x,y) = d(x,y) \le \mu
  + \varepsilon$ (perché la metrica è intrinseca) possiamo dire che
  $\forall (x,y) \exists \gamma_{(x,y)}$ tale che $\len ^d \gamma \le
  \mu + 2 \varepsilon$. Scegliamo una curva per ogni coppia di punti e
  definiamo
  \[ \Gamma = \set{\gamma _{(x,y)} :\; (x,y) \in P} \]

  Senza perdere di generalità possiamo chiedere che, se la curva
  $\gamma \in \Gamma$ ha lunghezza $\alpha (\mu + 2
  \varepsilon )$, allora $\len ^d \pa{ \gamma _{|\bra{s,t}}} = \alpha
  (t-s)$. Tutte le curve $\gamma$ avranno domino $\bra{0,\mu
    + 2 \varepsilon}$

  Definiamo ora, al variare di $t\in \bra{0,\mu + 2 \varepsilon}$
  \[ G(t) = \set{\gamma (t) | \; \gamma \in \Gamma} \;\;\;\; \bar G(t)
  = \obar{ G(t)} \]

  \`E evidente che $\bar G(0) = A$ e $\bar G(\mu + 2 \varepsilon) =
  C$, vogliamo ora dimostrare che $\bar G:\; \bra{0,\mu + 2
    \varepsilon} \to C_s(M)$, \`e continua e ha lunghezza minore di
  $\mu + 2 \varepsilon$.
  
  Dimostriamo che $\forall s<t \in \bra{0,\mu + 2 \varepsilon}$ si ha
  $d_H(\bar G(s),\bar G(t)) = d_H(G(s),G(t)) \le t-s$:
  \[ \forall \gamma(s) \in G(s) \; d_{G(t)}(\gamma(s)) = \inf _{y \in
    G(t)} d(\gamma(s),y) \le d(\gamma(s),\gamma(t)) = \alpha
  _{\gamma} (t-s) \le t-s \]
  Ripetendo lo stesso ragionamento per $G(s)$ otteniamo
  \[ d_H(G(s), G(t)) = \max\set{\sup_{x\in G(t)} d_{G(s)}(x) , \sup
    _{x\in G(s)} (x) d_{G(t)} } \le t-s \]
  Questo implica che $\bar G$ è $1$-Lipschitz e quindi
  continua. D'altra parte si ha che per ogni $t_0< t_1< ... < t_n \in
  \bra{0,\mu + 2 \varepsilon}$ 
  \[ \sum _{i=1} ^n d_H(\bar G(t_{i-1}), \bar G(t_i)) \le \sum _{i=1}
  ^n (t_i - t_{i-1}) = t_n - t_0 \le \mu + 2\varepsilon \]
  Quindi $\len ^{d_H}(\bar G) \le \mu + 2 \varepsilon$.
  Essendo $\bar G$ una curva continua in $C_s(M)$ che congiunge $A$ e
  $C$ si ha $d_H ^g (A,C) \le \mu + 2\varepsilon $, quindi
  \[ \mu = d_H (A,C) \le d_H^g(A,C) \le \mu + 2\varepsilon \]
  Mandando $\varepsilon \to 0$ si ha l'uguaglianza cercata.

  Dimostriamo l'altra implicazione: siano $a,c\in M$ e sia $\mu =
  d(a,c)$ consideriamo i razionali nella forma
  \[ Q = \set{ \mu \frac{k}{2^n}|\; 0< k <2^n\; k\text{ dispari}} \cup
  \set{0,\mu}\]

  E definiamo, induttivamente $\tilde \gamma:\; Q \to M$ in modo che
  $d(\tilde \gamma (t), \tilde \gamma (s)) < \abs{s-t} + \varepsilon
  \frac{\abs{s-t}}{\mu}$.

  Iniziamo definendo $\tilde\gamma \pa{\mu \frac{0}{2^0}} = a$, $\tilde\gamma
  \pa{\mu \frac{1}{2^0}} = c$, è evidente la proprietà sulla distanza.

  Supponendo di aver definito $\tilde \gamma (\mu \frac{k}{2^{n-1}})$
  con $0 \le k \le 2^{n-1}$ definiamo $\tilde \gamma$ per $\mu
  \frac{k}{2^n}$ con $k$ dispari. Per ipotesi induttiva sono definiti
  $x = \tilde \gamma\pa{\mu \frac{k-1}{2^n}}$ e $y = \tilde
  \gamma\pa{\mu \frac{k+1}{2^n}}$, sia quindi $G$ una curva nella
  metrica di Hausdorff che congiunge gli insiemi $\set{x}$ e $\set{y}$
  di lunghezza minore di $\frac{k+1}{2^n} - \frac{k-1}{2^n} +
  \frac{\varepsilon}{2^{n-1}} = \frac{1}{2^{n-1}} +
  \frac{\varepsilon}{2^{n-1}}$ (lo possiamo fare perché $d\pa{x,y} <
  \frac{\mu}{2^{n-1}} + \frac{\varepsilon}{2^{n-1}}$, la
  disuguaglianza è stretta, $d_H(\set{x},\set{y}) = d(x,y)$ e la
  metrica $d_H$ è intrinseca) e parametrizzata in modo che $d_H(G(s),
  G(t)) = \abs{t-s}$ con $G(0) = x$. Scegliamo allora un punto $z =
  \tilde \gamma \pa{\frac{k}{2^n}}$ in $G\pa{\frac{1}{2^n}}$, si deve
  avere necessariamente che $d(x,z) \le \frac{\mu}{2^n} +
  \frac{\varepsilon}{2^n}$ e $d(y,z) \le \frac{\mu}{2^n} +
  \frac{\varepsilon}{2^n}$. La disuguaglianza con gli altri punti già
  scelti vale applicando la proprietà triangolare.

  Abbiamo quindi definito una curva $\tilde \gamma: \; Q \to M$, data
  la stima sulla distanza dei punti nell'immagine possiamo estendere
  questa funzione, per continuità, ad una curva $\gamma: \bra{0,\mu}
  \to M$ continua. Usando ancora la stima sulla distanza dei punti
  possiamo maggiorare la lunghezza di questa curva con $\mu +
  \varepsilon$, quindi
  \[ \mu = d(a,c) \le d^g(a,c) \le \len^d (\gamma) \le \mu +
  \varepsilon \]
  Mandando $\varepsilon$ a zero si ha l'altra implicazione.
\end{proof}

Dimostriamo ora un risultato sull'esistenza di geodetiche in $(M,d)$
spazio metrico completo
\begin{mylem}
  Dato $K\subseteq M$ compatto connesso nella topologia indotta dalla
  metrica $d^g$ allora $\forall x,y \in K$ esiste la geodetica che li
  congiunge nella metrica indotta da $d$.
\end{mylem}
\begin{proof}
  Osservo che $K$ è compatto anche nella topologia indotta da $d$
  (vedi osservazione \ref{oss:topologiagedoeticafine}).

  Sia $\mu = d^g(x,y)$ e $\pa{\gamma _n}_{n \in \mathbb{N}} \subseteq
  \Gamma (x,y)$ una successione di curve continue tali che $\len
  \gamma _n \le \mu + \frac{1}{2^n}$. A meno di riparametrizzare posso
  chidere che $\forall n \in \mathbb{N}$ sia $\gamma _n :\;
  \bra{0,\mu} \to K$ con $\len ^d \gamma _{|\bra{s,t}} = \frac{\len ^d
    \gamma _n}{\mu}\pa{t-s} = \alpha _\gamma \pa{s-t}$, osservo che
  $\alpha _\gamma = \frac{\len ^d \gamma _n}{\mu} \le 2$.

  Le funzioni $\pa{\gamma _n}_{n \in \mathbb{N}}$ sono equicontinue
  (perché tutte Lipschitziane di constante minore di $2$),
  equilimitate (perché a valori in $C_s(K)$ compatto) e definite sul
  compatto $\bra{0,\mu}$. Quindi, per il teorema di Ascoli-Arzelà
  esiste una sottosuccessione $\pa{\gamma _{n_k}} _{n_k \in
    \mathbb{N}}$ convergente uniformemente ad una funzione $\gamma$.

  È evidente che $\gamma \in \Gamma (x,y)$, ci basta dimostare che
  $\len ^d \gamma = \mu$. Sia quindi $\set{ t_0 < t_1<... < t_n}
  \subseteq \bra{0,\mu}$, per ogni $\varepsilon > 0$ sia $\bar k$ tale
  che per ogni $k >\bar k$ $\norm{\gamma_{n_k} - \gamma} <
  \frac{\varepsilon}{n}$, allora
  \begin{align*}
  \sum _{i=1} ^n d\pa{\gamma(t_{i-1}),\gamma(t_i)} & \le \sum _{i=1}
  ^n\bra{ d\pa{\gamma(t_{i-1}),\gamma_{n_k}(t_{i-1})} +
    d\pa{\gamma_{n_k}(t_{i-1}), \gamma_{n_k}(t_i)} + d\pa{\gamma_{n_k}(t_i,
      \gamma(t_i)} } \\ 
  & \le \sum _{i=1} ^n \bra{ 2\frac{\varepsilon}{n} +
    d\pa{\gamma_{n_k}(t_{i-1}), \gamma_{n_k}(t_i)}} \\
  & \le 2\varepsilon + \len^d \gamma _{n_k} \le 2 \varepsilon + \mu +
  \frac{1}{2^{n_k}}
  \end{align*}
  Mandando $k \to \infty$ e $\varepsilon \to 0$ si ottiene quindi
  \[ \sum _{i=1} ^n d\pa{\gamma(t_{i-1}),\gamma(t_i)} \le \mu \]
  Facendo il $\sup$ su tutti i sottinsiemi finiti di $\bra{0,\mu}$
  otteniamo quindi
  \[ \len ^d \gamma \le \mu \]
  D'altra parte $\mu = d^g (x,y)$, quindi $\len ^d (\gamma) = \mu$ e
  $\gamma$ è la geodetica cercata.
\end{proof}

Quindi una condizione sufficiente per l'esistenza di geodetiche è che
lo spazio metrico sia compatto e intrinseco, per esempio $C_s(\Omega)$
con $\Omega$ compatto e $d$ intrinseca.

\begin{myes}
\label{es:duegeodetiche}  
Ovviamente le geodetiche possono non essere uniche, basta pensare ad
una ``rete'': sia $R  = \bigcup _{n \in \mathbb{Z}} \set{(n,y) \mid y
  \in \mathbb{R}} \cup \bigcup _{n \in \mathbb{Z}} \set{(x,n) \mid x
  \in \mathbb{R}} \subseteq \mathbb{R}^2$ con la metrica euclidea. I
punti $(0,0)$ e $(1,1)$ possono essere congiunti con due geodetiche
distinte 

\begin{figure}[h]
  \centering
  \begin{pdfpic}
    \begin{pspicture}(0,0)(10,10)
      \psgrid[subgriddiv=0, gridlabels=0pt, gridwidth=0.02cm](-1,-1)(3,3)
      \psdot[dotsize=0.2cm](0,0)
      \rput(-0.5,0.2){$(0,0)$}
      \psdot[dotsize=0.2cm](1,1)
      \rput(1.5,1.2){$(1,1)$}
      \psline[linewidth=0.05cm]{->}(0,0)(0,1)(1,1)
      \psline[linewidth=0.05cm]{->}(0,0)(1,0)(1,1)
    \end{pspicture}
  \end{pdfpic}
  \caption{Le due geodetiche tra $(0,0)$ e $(1,1)$ dell'esempio \ref{es:duegeodetiche}}
  \label{fig:doppiageodeticagriglia}
\end{figure}
\end{myes}


Nel cercare l'esistenza di geodetiche può tornare utile il segunte
lemma
\begin{mylem}
  Dati $x,y \in M$ esiste una geodetica tra di loro in $M$ se e solo
  se esiste in $B(x,d^g(x,y) + \delta)$ con $\delta > 0$
  qualsiasi.
\end{mylem}
\begin{proof}
  Il ``solo se'' è facile, infatti tutti i punti di una geodetica in
  $M$ avranno distanza minore di $d^g(x,y)$ da $x$ e quindi staranno
  nella palla.

  Supponiamo, quindi, che esista la geodetica in in $B := B(x,d^g(x,y) +
  \delta)$ per un qualche $\delta > 0$. Questa sarà una
  geodetica anche in $M$ se e solo se $d_{|B}^g (x,y) = d^g(x,y)$, ma
  $\forall 0 < \varepsilon < \delta$ esiste, in $M$, una curva di
  lunghezza minore di $d^g(x,y) + \varepsilon$, per lo stesso
  ragionamento del punto precedente tutti i punti devono stare in $B$
  e quindi $d_{|B}^g (x,y) < d^g(x,y) + \varepsilon$, passando
  all'estremo inferiore si ha la tesi.
\end{proof}


Vediamo ora che, con opportune ipotesi, nella distanza di Hausdorff
esiste sempre la geodetica fra insiemi compatti, ma ne possono
esistere più che numerabili.

\begin{mypro}
  Se in $M$ le palle chiuse sono compatte allora esiste sempre la
  geodetica fra $A,C \in K(M)$.
\end{mypro}
\begin{proof}
  Per il lemma precedente la geodetica si può cercare in\footnote{Per
    ora cerco la geodetica in $C_s(M)$, poi dimostrerò che tale
    geodetica in realtà ha valori in $K(M)$}
  \[ \set{D \in C_s(M) \mid \; d_H(A,D) \le d_H(A,C) + \delta= \mu +
    \delta } \]

  Dalla relazione $d_H(A,D) \le \mu + \delta \Rightarrow D \subseteq A
  + \bar B _{\mu + \delta}$, ricordando che (per compattezza) $A \subseteq
  B(x_0,\rho)$ (per qualche $x_0 \in M$, $\rho >0$) si ha che possiamo
  cercare i punti di una geodetica fra i sottoinsiemi di
  \[ \Omega = \obar{B(x_0,\rho)} + \bar B _{\mu + \delta} = \obar{ B
    (x_0, \rho + \mu + \delta) } \]

  Ma $\Omega$ è compatto per ipotesi e quindi, per il lemma
  precedente, esiste una geodetica in $C_s(\Omega)$, osservando che
  $C_s(\Omega) = K(\Omega) \subseteq K(M)$ (perché sottinsiemi chiusi
  in un compatto) si ha che la geodetica trovata ha valori in $K(M)$.
\end{proof}

Come preannunciato le geodetiche possono essere anche più che
numerabili. Vediamo un esempio
\begin{myes}[{\cite[Esempio 2.17]{DuciMennucci2007}}]
  Considero $M = \Omega = \mathbb{R}^2$ con la distanza euclidea $d$,
  osservo che questa distanza è intrinseca e, di conseguenza, lo sarà
  anche $d_H$.

  Siano $A = \set{(0,y)\mid \; 0 \le y \le 2}$, $C = \set{(2,y)\mid \;
    0 \le y \le 1}$ e $D_t = \set{(1,y) \mid \; 0 \le y \le
    \frac{3}{2}} \cup \set{ (x,0) \mid \; 1 \le x \le t}$ al variare
  di $t \in \bra{1,\frac{\sqrt{5}}{2}}$.

  \begin{figure}[h]
    \centering
    
    \begin{pdfpic}
   \begin{pspicture}(0,0)(3,3)
     \psline[linewidth=0.04cm](0.0,0.0)(0.0,2.0)
     \rput(-0.3,2){$A$}
     \psline[linewidth=0.04cm](2.0,0.0)(2.0,1.0)
     \rput(2.3,1){$C$}
     \psline[linewidth=0.04cm](1.0,0.0)(1.0,1.5)
     \psline[linewidth=0.04cm](0.98,0.0)(1.1,0.0)
     \rput(1.35,0.1){$D_t$}
     \psarc[linewidth=0.02cm,linestyle=dashed](0.0,2.0){1.118}{360.0}{180.0}
     \psarc[linewidth=0.02cm,linestyle=dashed](0.0,0.0){1.118}{180.0}{360.0}
     \psline[linewidth=0.02cm,linestyle=dashed](-1.118,0)(-1.118,2)
     \psline[linewidth=0.02cm,linestyle=dashed](+1.118,0)(+1.118,2)
     \psarc[linewidth=0.02cm,linestyle=dashed](2.0,1.0){1.118}{360.0}{180.0}
     \psarc[linewidth=0.02cm,linestyle=dashed](2.0,0.0){1.118}{180.0}{360.0}
     \psline[linewidth=0.02cm,linestyle=dashed](0.88197,0)(0.88197,1)
     \psline[linewidth=0.02cm,linestyle=dashed](3.118,0)(3.118,1)
   \end{pspicture}
\end{pdfpic}



    \caption{Gli insiemi $A,C,D_t$ e $A + \bar B _{\frac{\sqrt{5}}{2}},
        C + \bar B _{\frac{\sqrt{5}}{2}}$}
      \label{fig:esempioinfinitegeodetiche}
  \end{figure}
  %TODO: disegno
  Allora $\forall t$ si ha
  \[ d_H(A, D_t) = d_H (C, D_t) = \frac{\sqrt{5}}{2} = \frac{1}{2}
  d_H(A,C) \]
  Quindi, per ogni $t$, possiamo scegliere una geodetica $\gamma_t ^1$
  che congiunge $A$ e $D_t$, una $\gamma _t ^2$ che congiunge $C$ e
  $D_t$, incollandole otteniamo una geodetica fra $A$ e $C$. Quindi,
  abbiamo geodetiche distinte per ogni $t$ distinto e quindi più che
  numerabili geodetiche.
\end{myes}




% \newpage
% \begin{mydef}[Convessità di Menger]
%   Uno spazio metrico $M$ si dice convesso secondo Menger se, dati
%   comunque $x,y \in M$ distinti esiste $z\neq x,y$ tale che
%   \[ d(x,z) + d(z,y) = d(x,y) \]
% \end{mydef}


% Sotto opportune ipotesi uno spazio è convesso secondo Menger se e solo
% se la metrica è intrinseca ed esiste sempre la geodetica fra due
% punti. Cioè vale il seguente teorema:

% \begin{myteo}[{\cite[Teorema 2.6.2]{papadopoulos2013metric}}]
%   Sia $M,d$ uno spazio metrico in cui ogni palla chiusa è
%   compatta. Allora le seguenti condizioni sono equivalenti:
%   \begin{enumerate}
%   \item $M$ è convesso secondo Menger
%   \item $\forall x,y \in M$ esiste $z\in M$ tale che 
%     \[ d(x,z) = d(y,z) = \frac{1}{2} d(x,y) \]
%   \item $\forall x,y \in M$ e $\forall \lambda \in \bra{0,1}$ esiste
%     $z\in M$ tale che $d(x,z) = \lambda d(x,y)$, $d(y,z) = (1-\lambda)
%     d(x,y)$ 
%   \item Dati $x,y \in M$ esiste $\gamma \in \Gamma(x,y)$ tale che
%     $\len ^d (\gamma) = d(x,y)$
%   \end{enumerate}
% \end{myteo}
% % \begin{proof}
% %   TODO
% % \end{proof}

% Vogliamo applicare il teorema precedente a $K(\Omega),d_H$ per
% dimostrare che se $d$ è intrinseca dove esiste sempre la geodetica fra
% due punti allora anche $d_H$ è intrinseca ed esiste sempre la
% geodetica fra due insiemi.

% \begin{mylem}\cite[Proposizione 2.16]{DuciMennucci2007}
%   Sia $\Omega$ completo. Dati $A,C \in K(\Omega)$ con $d_H(A,C) <
%   \infty$ per ogni $\lambda \in \bra{0,1}$ esiste $D\in K(\Omega)$
%   tale che
%   \[ d_H(A,D) = \lambda d_H(A,C) \; , \;\;  d_H(D,C) = (1-\lambda)
%   d_H(A,C) \] 
% \end{mylem}
% \begin{proof}
%   Sia $\mu = d_H(A,C)$

%   Consideriamo l'insieme
%   \[ D := \set{z\mid \exists x \in A, y\in C, d(x,y) \le \mu, d(x,z)
%     \le \lambda \mu, d(y,z) \le (1 - \lambda) \mu }\]
%   Questo insieme è non vuoto, infatti (per compattezza di $A,C$)
%   esistono sempre $x,y$ tali che $d(x,y) \le \mu$, allora $z$ che
%   soddisfi le condizioni esiste perché $d$ è intrinseca e ci basta
%   considerare una geodetica tra $x$ e $y$.

%   Dimostro che $d(A,D) \le \lambda \mu$: per come abbiamo definito $D$
%   si ha che $\forall z \in D\; d_A(z) \le \lambda \mu$, quindi
%   \[ \sup _{z\in D} d_A(z) \le \lambda \mu \] D'altra parte, dato
%   $x\in A$ esiste $y\in B$ tale che $d(x,y) \le \mu$, allora esiste
%   una geodetica tra $x$ e $y$ e quindi anche un punto $z$ tale che
%   $d(x,z) \le \lambda \mu$ da cui
%   \[ \sup _{x \in A} d_D(x) \le \lambda \mu \]
%   Quindi concludiamo $d_H(A,D) \le \lambda \mu$, con un ragionamento
%   analogo possiamo concludere che $d_H(D,C) \le (1 - \lambda) \mu$.
%   A questo punto osserviamo che nella relazione
%   \[ \mu = d_H(A,C) \le d_H(A,D) + d_H(D,C) \le \lambda \mu + (1 -
%   \lambda) \mu = \mu \]
%   I segni di disuguaglianza devono essere uguaglianze e quindi
%   otteniamo $d_H(A,D) = \lambda \mu$ e $d_H(D,C) = (1 - \lambda)
%   \mu)$.

%   Ci basta ora dimostrare che $D$ è compatto.
% \end{proof}

% \begin{mynot}
%   È semplice vedere che $d_H$ intrinseca ed esiste la geodetica
%   $\Rightarrow$ $d$ intrinseca ed esiste la geodetica. Quindi dobbiamo
%   chiedere che $d$ sia intrinseca.
% \end{mynot}


% Reference: \cite[p.12-14]{DuciMennucci2007}

\section{Media basata sulle distanze}

Sia $(M,d)$ spazio metrico.

Dati $a_1,a_2,... a_n \in M$ considero la quanità, al variare di $a
\in m$
\[ m_A (a) = \sum _{i = 1} ^n d(a,a_i)^2 \]

Ha senso discutere se esiste $a$ e, nel caso, se è unico. Osservo che
non si ha necessariamente l'unicità, mi basta considerare nella
distanza geodetica indotta due punti che possono essere collegati da
più di una geodetica, allora i punti medi delle geodetiche saranno
minimi per tale quantità, nell'esempio \ref{es:duegeodetiche} i punti
$(0,1)$ e $(1,0)$ sono i minimi di $m_A$.

\newpage

\bibliographystyle{alpha}
\bibliography{Selected_Topics_on_Analysis_in_Metric_Sp,Banach-like_metrics_and_metrics_of_compact_sets,Metric_Spaces_Convexity_and_Nonpositive}


\newpage

Cose da inserire:
\begin{itemize}
\item Cenno di dimostrazione che $d^g$ è una distanza
\end{itemize}

Cose possibili da fare:

\begin{itemize}
\item Vedere quando, nelle definizioni di $d_H$ gli $\inf$ e $\sup$ si
  possono trasformare in $\min$ e $\max$.
\item se per un $x \in M$ e $\forall \rho > 0$ l'insieme $\set{ y \mid
    d(x,y) \le \rho}$ è compatto allora $(M,d)$ è completo
\end{itemize}


Cose saltate che potrebbero essere inserite
\begin{itemize}
\item skeleton
  \begin{itemize}
  \item Lo skeleton è compatto
  \item caratterizzazione coi punti dove non esiste il gradiente di
    $d_A$
  \end{itemize}
\item Convergenza di kuratowski (ambrosio tilli p.77) è implicata
  dalla Hausdorff ed è equivalente in compatti
\item Distanza con segno: $b_A(x) = d_A(x) - d_{^cA}(x)$
\end{itemize}


Cose saltate che non vorrei inserire:
\begin{itemize}
\item $d_A$ è Frechet differenziabile q.o. e $\abs{\nabla d_A} \le 1$
\end{itemize}
\end{document}

